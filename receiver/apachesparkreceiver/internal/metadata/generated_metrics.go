// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"time"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/receiver"
)

// AttributeDirection specifies the a value direction attribute.
type AttributeDirection int

const (
	_ AttributeDirection = iota
	AttributeDirectionIn
	AttributeDirectionOut
)

// String returns the string representation of the AttributeDirection.
func (av AttributeDirection) String() string {
	switch av {
	case AttributeDirectionIn:
		return "in"
	case AttributeDirectionOut:
		return "out"
	}
	return ""
}

// MapAttributeDirection is a helper map of string to AttributeDirection attribute value.
var MapAttributeDirection = map[string]AttributeDirection{
	"in":  AttributeDirectionIn,
	"out": AttributeDirectionOut,
}

// AttributeExecutorTaskResult specifies the a value executor_task_result attribute.
type AttributeExecutorTaskResult int

const (
	_ AttributeExecutorTaskResult = iota
	AttributeExecutorTaskResultCompleted
	AttributeExecutorTaskResultFailed
)

// String returns the string representation of the AttributeExecutorTaskResult.
func (av AttributeExecutorTaskResult) String() string {
	switch av {
	case AttributeExecutorTaskResultCompleted:
		return "completed"
	case AttributeExecutorTaskResultFailed:
		return "failed"
	}
	return ""
}

// MapAttributeExecutorTaskResult is a helper map of string to AttributeExecutorTaskResult attribute value.
var MapAttributeExecutorTaskResult = map[string]AttributeExecutorTaskResult{
	"completed": AttributeExecutorTaskResultCompleted,
	"failed":    AttributeExecutorTaskResultFailed,
}

// AttributeGcType specifies the a value gc_type attribute.
type AttributeGcType int

const (
	_ AttributeGcType = iota
	AttributeGcTypeMajor
	AttributeGcTypeMinor
)

// String returns the string representation of the AttributeGcType.
func (av AttributeGcType) String() string {
	switch av {
	case AttributeGcTypeMajor:
		return "major"
	case AttributeGcTypeMinor:
		return "minor"
	}
	return ""
}

// MapAttributeGcType is a helper map of string to AttributeGcType attribute value.
var MapAttributeGcType = map[string]AttributeGcType{
	"major": AttributeGcTypeMajor,
	"minor": AttributeGcTypeMinor,
}

// AttributeJobStageResult specifies the a value job_stage_result attribute.
type AttributeJobStageResult int

const (
	_ AttributeJobStageResult = iota
	AttributeJobStageResultCompleted
	AttributeJobStageResultFailed
	AttributeJobStageResultSkipped
)

// String returns the string representation of the AttributeJobStageResult.
func (av AttributeJobStageResult) String() string {
	switch av {
	case AttributeJobStageResultCompleted:
		return "completed"
	case AttributeJobStageResultFailed:
		return "failed"
	case AttributeJobStageResultSkipped:
		return "skipped"
	}
	return ""
}

// MapAttributeJobStageResult is a helper map of string to AttributeJobStageResult attribute value.
var MapAttributeJobStageResult = map[string]AttributeJobStageResult{
	"completed": AttributeJobStageResultCompleted,
	"failed":    AttributeJobStageResultFailed,
	"skipped":   AttributeJobStageResultSkipped,
}

// AttributeJobTaskResult specifies the a value job_task_result attribute.
type AttributeJobTaskResult int

const (
	_ AttributeJobTaskResult = iota
	AttributeJobTaskResultCompleted
	AttributeJobTaskResultFailed
	AttributeJobTaskResultSkipped
)

// String returns the string representation of the AttributeJobTaskResult.
func (av AttributeJobTaskResult) String() string {
	switch av {
	case AttributeJobTaskResultCompleted:
		return "completed"
	case AttributeJobTaskResultFailed:
		return "failed"
	case AttributeJobTaskResultSkipped:
		return "skipped"
	}
	return ""
}

// MapAttributeJobTaskResult is a helper map of string to AttributeJobTaskResult attribute value.
var MapAttributeJobTaskResult = map[string]AttributeJobTaskResult{
	"completed": AttributeJobTaskResultCompleted,
	"failed":    AttributeJobTaskResultFailed,
	"skipped":   AttributeJobTaskResultSkipped,
}

// AttributeLocation specifies the a value location attribute.
type AttributeLocation int

const (
	_ AttributeLocation = iota
	AttributeLocationOnHeap
	AttributeLocationOffHeap
)

// String returns the string representation of the AttributeLocation.
func (av AttributeLocation) String() string {
	switch av {
	case AttributeLocationOnHeap:
		return "on_heap"
	case AttributeLocationOffHeap:
		return "off_heap"
	}
	return ""
}

// MapAttributeLocation is a helper map of string to AttributeLocation attribute value.
var MapAttributeLocation = map[string]AttributeLocation{
	"on_heap":  AttributeLocationOnHeap,
	"off_heap": AttributeLocationOffHeap,
}

// AttributePoolMemoryType specifies the a value pool_memory_type attribute.
type AttributePoolMemoryType int

const (
	_ AttributePoolMemoryType = iota
	AttributePoolMemoryTypeDirect
	AttributePoolMemoryTypeMapped
)

// String returns the string representation of the AttributePoolMemoryType.
func (av AttributePoolMemoryType) String() string {
	switch av {
	case AttributePoolMemoryTypeDirect:
		return "direct"
	case AttributePoolMemoryTypeMapped:
		return "mapped"
	}
	return ""
}

// MapAttributePoolMemoryType is a helper map of string to AttributePoolMemoryType attribute value.
var MapAttributePoolMemoryType = map[string]AttributePoolMemoryType{
	"direct": AttributePoolMemoryTypeDirect,
	"mapped": AttributePoolMemoryTypeMapped,
}

// AttributeSource specifies the a value source attribute.
type AttributeSource int

const (
	_ AttributeSource = iota
	AttributeSourceLocal
	AttributeSourceRemote
)

// String returns the string representation of the AttributeSource.
func (av AttributeSource) String() string {
	switch av {
	case AttributeSourceLocal:
		return "local"
	case AttributeSourceRemote:
		return "remote"
	}
	return ""
}

// MapAttributeSource is a helper map of string to AttributeSource attribute value.
var MapAttributeSource = map[string]AttributeSource{
	"local":  AttributeSourceLocal,
	"remote": AttributeSourceRemote,
}

// AttributeStageTaskResult specifies the a value stage_task_result attribute.
type AttributeStageTaskResult int

const (
	_ AttributeStageTaskResult = iota
	AttributeStageTaskResultCompleted
	AttributeStageTaskResultFailed
	AttributeStageTaskResultKilled
)

// String returns the string representation of the AttributeStageTaskResult.
func (av AttributeStageTaskResult) String() string {
	switch av {
	case AttributeStageTaskResultCompleted:
		return "completed"
	case AttributeStageTaskResultFailed:
		return "failed"
	case AttributeStageTaskResultKilled:
		return "killed"
	}
	return ""
}

// MapAttributeStageTaskResult is a helper map of string to AttributeStageTaskResult attribute value.
var MapAttributeStageTaskResult = map[string]AttributeStageTaskResult{
	"completed": AttributeStageTaskResultCompleted,
	"failed":    AttributeStageTaskResultFailed,
	"killed":    AttributeStageTaskResultKilled,
}

type metricSparkBlockManagerDiskUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.block_manager.disk.usage metric with initial data.
func (m *metricSparkBlockManagerDiskUsage) init() {
	m.data.SetName("spark.block_manager.disk.usage")
	m.data.SetDescription("Disk space used by the BlockManager.")
	m.data.SetUnit("mb")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkBlockManagerDiskUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkBlockManagerDiskUsage) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkBlockManagerDiskUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkBlockManagerDiskUsage(cfg MetricConfig) metricSparkBlockManagerDiskUsage {
	m := metricSparkBlockManagerDiskUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkBlockManagerMemoryRemaining struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.block_manager.memory.remaining metric with initial data.
func (m *metricSparkBlockManagerMemoryRemaining) init() {
	m.data.SetName("spark.block_manager.memory.remaining")
	m.data.SetDescription("Memory remaining for the BlockManager.")
	m.data.SetUnit("mb")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkBlockManagerMemoryRemaining) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, locationAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("location", locationAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkBlockManagerMemoryRemaining) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkBlockManagerMemoryRemaining) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkBlockManagerMemoryRemaining(cfg MetricConfig) metricSparkBlockManagerMemoryRemaining {
	m := metricSparkBlockManagerMemoryRemaining{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkBlockManagerMemoryUsed struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.block_manager.memory.used metric with initial data.
func (m *metricSparkBlockManagerMemoryUsed) init() {
	m.data.SetName("spark.block_manager.memory.used")
	m.data.SetDescription("Memory used by the BlockManager.")
	m.data.SetUnit("mb")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkBlockManagerMemoryUsed) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, locationAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("location", locationAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkBlockManagerMemoryUsed) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkBlockManagerMemoryUsed) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkBlockManagerMemoryUsed(cfg MetricConfig) metricSparkBlockManagerMemoryUsed {
	m := metricSparkBlockManagerMemoryUsed{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkCodeGeneratorCompilationAverageTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.code_generator.compilation.average_time metric with initial data.
func (m *metricSparkCodeGeneratorCompilationAverageTime) init() {
	m.data.SetName("spark.code_generator.compilation.average_time")
	m.data.SetDescription("Average time spent during CodeGenerator source code compilation operations.")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
}

func (m *metricSparkCodeGeneratorCompilationAverageTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkCodeGeneratorCompilationAverageTime) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkCodeGeneratorCompilationAverageTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkCodeGeneratorCompilationAverageTime(cfg MetricConfig) metricSparkCodeGeneratorCompilationAverageTime {
	m := metricSparkCodeGeneratorCompilationAverageTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkCodeGeneratorCompilationCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.code_generator.compilation.count metric with initial data.
func (m *metricSparkCodeGeneratorCompilationCount) init() {
	m.data.SetName("spark.code_generator.compilation.count")
	m.data.SetDescription("Number of source code compilation operations performed by the CodeGenerator.")
	m.data.SetUnit("{ compilations }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkCodeGeneratorCompilationCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkCodeGeneratorCompilationCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkCodeGeneratorCompilationCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkCodeGeneratorCompilationCount(cfg MetricConfig) metricSparkCodeGeneratorCompilationCount {
	m := metricSparkCodeGeneratorCompilationCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkCodeGeneratorGeneratedClassAverageSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.code_generator.generated_class.average_size metric with initial data.
func (m *metricSparkCodeGeneratorGeneratedClassAverageSize) init() {
	m.data.SetName("spark.code_generator.generated_class.average_size")
	m.data.SetDescription("Average class size of the classes generated by the CodeGenerator.")
	m.data.SetUnit("bytes")
	m.data.SetEmptyGauge()
}

func (m *metricSparkCodeGeneratorGeneratedClassAverageSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkCodeGeneratorGeneratedClassAverageSize) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkCodeGeneratorGeneratedClassAverageSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkCodeGeneratorGeneratedClassAverageSize(cfg MetricConfig) metricSparkCodeGeneratorGeneratedClassAverageSize {
	m := metricSparkCodeGeneratorGeneratedClassAverageSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkCodeGeneratorGeneratedClassCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.code_generator.generated_class.count metric with initial data.
func (m *metricSparkCodeGeneratorGeneratedClassCount) init() {
	m.data.SetName("spark.code_generator.generated_class.count")
	m.data.SetDescription("Number of classes generated by the CodeGenerator.")
	m.data.SetUnit("{ classes }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkCodeGeneratorGeneratedClassCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkCodeGeneratorGeneratedClassCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkCodeGeneratorGeneratedClassCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkCodeGeneratorGeneratedClassCount(cfg MetricConfig) metricSparkCodeGeneratorGeneratedClassCount {
	m := metricSparkCodeGeneratorGeneratedClassCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkCodeGeneratorGeneratedMethodAverageSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.code_generator.generated_method.average_size metric with initial data.
func (m *metricSparkCodeGeneratorGeneratedMethodAverageSize) init() {
	m.data.SetName("spark.code_generator.generated_method.average_size")
	m.data.SetDescription("Average method size of the classes generated by the CodeGenerator.")
	m.data.SetUnit("bytes")
	m.data.SetEmptyGauge()
}

func (m *metricSparkCodeGeneratorGeneratedMethodAverageSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkCodeGeneratorGeneratedMethodAverageSize) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkCodeGeneratorGeneratedMethodAverageSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkCodeGeneratorGeneratedMethodAverageSize(cfg MetricConfig) metricSparkCodeGeneratorGeneratedMethodAverageSize {
	m := metricSparkCodeGeneratorGeneratedMethodAverageSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkCodeGeneratorGeneratedMethodCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.code_generator.generated_method.count metric with initial data.
func (m *metricSparkCodeGeneratorGeneratedMethodCount) init() {
	m.data.SetName("spark.code_generator.generated_method.count")
	m.data.SetDescription("Number of methods generated by the CodeGenerator.")
	m.data.SetUnit("{ methods }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkCodeGeneratorGeneratedMethodCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkCodeGeneratorGeneratedMethodCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkCodeGeneratorGeneratedMethodCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkCodeGeneratorGeneratedMethodCount(cfg MetricConfig) metricSparkCodeGeneratorGeneratedMethodCount {
	m := metricSparkCodeGeneratorGeneratedMethodCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkCodeGeneratorSourceCodeAverageSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.code_generator.source_code.average_size metric with initial data.
func (m *metricSparkCodeGeneratorSourceCodeAverageSize) init() {
	m.data.SetName("spark.code_generator.source_code.average_size")
	m.data.SetDescription("Average size of the source code generated by a CodeGenerator code generation operation.")
	m.data.SetUnit("bytes")
	m.data.SetEmptyGauge()
}

func (m *metricSparkCodeGeneratorSourceCodeAverageSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkCodeGeneratorSourceCodeAverageSize) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkCodeGeneratorSourceCodeAverageSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkCodeGeneratorSourceCodeAverageSize(cfg MetricConfig) metricSparkCodeGeneratorSourceCodeAverageSize {
	m := metricSparkCodeGeneratorSourceCodeAverageSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkCodeGeneratorSourceCodeOperations struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.code_generator.source_code.operations metric with initial data.
func (m *metricSparkCodeGeneratorSourceCodeOperations) init() {
	m.data.SetName("spark.code_generator.source_code.operations")
	m.data.SetDescription("Number of source code generation operations performed by the CodeGenerator.")
	m.data.SetUnit("{ operations }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkCodeGeneratorSourceCodeOperations) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkCodeGeneratorSourceCodeOperations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkCodeGeneratorSourceCodeOperations) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkCodeGeneratorSourceCodeOperations(cfg MetricConfig) metricSparkCodeGeneratorSourceCodeOperations {
	m := metricSparkCodeGeneratorSourceCodeOperations{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDagSchedulerJobsActive struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.dag_scheduler.jobs.active metric with initial data.
func (m *metricSparkDagSchedulerJobsActive) init() {
	m.data.SetName("spark.dag_scheduler.jobs.active")
	m.data.SetDescription("Number of active jobs currently being processed by the DAGScheduler.")
	m.data.SetUnit("{ jobs }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDagSchedulerJobsActive) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDagSchedulerJobsActive) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDagSchedulerJobsActive) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDagSchedulerJobsActive(cfg MetricConfig) metricSparkDagSchedulerJobsActive {
	m := metricSparkDagSchedulerJobsActive{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDagSchedulerJobsCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.dag_scheduler.jobs.count metric with initial data.
func (m *metricSparkDagSchedulerJobsCount) init() {
	m.data.SetName("spark.dag_scheduler.jobs.count")
	m.data.SetDescription("Number of jobs that have been submitted to the DAGScheduler.")
	m.data.SetUnit("{ jobs }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDagSchedulerJobsCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDagSchedulerJobsCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDagSchedulerJobsCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDagSchedulerJobsCount(cfg MetricConfig) metricSparkDagSchedulerJobsCount {
	m := metricSparkDagSchedulerJobsCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDagSchedulerStages struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.dag_scheduler.stages metric with initial data.
func (m *metricSparkDagSchedulerStages) init() {
	m.data.SetName("spark.dag_scheduler.stages")
	m.data.SetDescription("Number of stages the DAGScheduler is either running or needs to run.")
	m.data.SetUnit("{ stages }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkDagSchedulerStages) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, schedulerWaitingAttributeValue bool, schedulerRunningAttributeValue bool) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutBool("scheduler_waiting", schedulerWaitingAttributeValue)
	dp.Attributes().PutBool("scheduler_running", schedulerRunningAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDagSchedulerStages) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDagSchedulerStages) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDagSchedulerStages(cfg MetricConfig) metricSparkDagSchedulerStages {
	m := metricSparkDagSchedulerStages{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkDagSchedulerStagesFailed struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.dag_scheduler.stages.failed metric with initial data.
func (m *metricSparkDagSchedulerStagesFailed) init() {
	m.data.SetName("spark.dag_scheduler.stages.failed")
	m.data.SetDescription("Number of failed stages run by the DAGScheduler.")
	m.data.SetUnit("{ stages }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkDagSchedulerStagesFailed) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkDagSchedulerStagesFailed) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkDagSchedulerStagesFailed) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkDagSchedulerStagesFailed(cfg MetricConfig) metricSparkDagSchedulerStagesFailed {
	m := metricSparkDagSchedulerStagesFailed{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorDiskUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.disk.usage metric with initial data.
func (m *metricSparkExecutorDiskUsage) init() {
	m.data.SetName("spark.executor.disk.usage")
	m.data.SetDescription("Disk space used by this executor for RDD storage.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkExecutorDiskUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorDiskUsage) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorDiskUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorDiskUsage(cfg MetricConfig) metricSparkExecutorDiskUsage {
	m := metricSparkExecutorDiskUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorGcOperations struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.gc.operations metric with initial data.
func (m *metricSparkExecutorGcOperations) init() {
	m.data.SetName("spark.executor.gc.operations")
	m.data.SetDescription("Number of garbage collection operations performed by the component.")
	m.data.SetUnit("{ gc_operations }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkExecutorGcOperations) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, gcTypeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("gc_type", gcTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorGcOperations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorGcOperations) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorGcOperations(cfg MetricConfig) metricSparkExecutorGcOperations {
	m := metricSparkExecutorGcOperations{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorGcTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.gc.time metric with initial data.
func (m *metricSparkExecutorGcTime) init() {
	m.data.SetName("spark.executor.gc.time")
	m.data.SetDescription("Total elapsed time during garbage collection operations performed by the component.")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkExecutorGcTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, gcTypeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("gc_type", gcTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorGcTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorGcTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorGcTime(cfg MetricConfig) metricSparkExecutorGcTime {
	m := metricSparkExecutorGcTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorGcTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.gc_time metric with initial data.
func (m *metricSparkExecutorGcTime) init() {
	m.data.SetName("spark.executor.gc_time")
	m.data.SetDescription("Elapsed time the JVM spent in garbage collection in this executor.")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkExecutorGcTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorGcTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorGcTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorGcTime(cfg MetricConfig) metricSparkExecutorGcTime {
	m := metricSparkExecutorGcTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorInputSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.input_size metric with initial data.
func (m *metricSparkExecutorInputSize) init() {
	m.data.SetName("spark.executor.input_size")
	m.data.SetDescription("Amount of data input for this executor.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkExecutorInputSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorInputSize) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorInputSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorInputSize(cfg MetricConfig) metricSparkExecutorInputSize {
	m := metricSparkExecutorInputSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorJvmMemory struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.jvm_memory metric with initial data.
func (m *metricSparkExecutorJvmMemory) init() {
	m.data.SetName("spark.executor.jvm_memory")
	m.data.SetDescription("Amount of memory used by the component's JVM.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkExecutorJvmMemory) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, locationAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("location", locationAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorJvmMemory) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorJvmMemory) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorJvmMemory(cfg MetricConfig) metricSparkExecutorJvmMemory {
	m := metricSparkExecutorJvmMemory{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorMemoryExecution struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.memory.execution metric with initial data.
func (m *metricSparkExecutorMemoryExecution) init() {
	m.data.SetName("spark.executor.memory.execution")
	m.data.SetDescription("Amount of execution memory currently used by the component.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkExecutorMemoryExecution) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, locationAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("location", locationAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorMemoryExecution) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorMemoryExecution) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorMemoryExecution(cfg MetricConfig) metricSparkExecutorMemoryExecution {
	m := metricSparkExecutorMemoryExecution{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorMemoryPool struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.memory.pool metric with initial data.
func (m *metricSparkExecutorMemoryPool) init() {
	m.data.SetName("spark.executor.memory.pool")
	m.data.SetDescription("Amount of pool memory currently used by the component.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkExecutorMemoryPool) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, poolMemoryTypeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("pool_memory_type", poolMemoryTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorMemoryPool) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorMemoryPool) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorMemoryPool(cfg MetricConfig) metricSparkExecutorMemoryPool {
	m := metricSparkExecutorMemoryPool{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorMemoryStorage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.memory.storage metric with initial data.
func (m *metricSparkExecutorMemoryStorage) init() {
	m.data.SetName("spark.executor.memory.storage")
	m.data.SetDescription("Amount of storage memory currently used by the component.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkExecutorMemoryStorage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, locationAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("location", locationAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorMemoryStorage) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorMemoryStorage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorMemoryStorage(cfg MetricConfig) metricSparkExecutorMemoryStorage {
	m := metricSparkExecutorMemoryStorage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorMemoryUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.memory.usage metric with initial data.
func (m *metricSparkExecutorMemoryUsage) init() {
	m.data.SetName("spark.executor.memory.usage")
	m.data.SetDescription("Storage memory used by this executor.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkExecutorMemoryUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorMemoryUsage) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorMemoryUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorMemoryUsage(cfg MetricConfig) metricSparkExecutorMemoryUsage {
	m := metricSparkExecutorMemoryUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorShuffleIoSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.shuffle.io.size metric with initial data.
func (m *metricSparkExecutorShuffleIoSize) init() {
	m.data.SetName("spark.executor.shuffle.io.size")
	m.data.SetDescription("Amount of data written and read during shuffle operations for this executor.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkExecutorShuffleIoSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorShuffleIoSize) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorShuffleIoSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorShuffleIoSize(cfg MetricConfig) metricSparkExecutorShuffleIoSize {
	m := metricSparkExecutorShuffleIoSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorStorageMemoryTotal struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.storage_memory.total metric with initial data.
func (m *metricSparkExecutorStorageMemoryTotal) init() {
	m.data.SetName("spark.executor.storage_memory.total")
	m.data.SetDescription("Total memory that can be used for storage.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkExecutorStorageMemoryTotal) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, locationAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("location", locationAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorStorageMemoryTotal) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorStorageMemoryTotal) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorStorageMemoryTotal(cfg MetricConfig) metricSparkExecutorStorageMemoryTotal {
	m := metricSparkExecutorStorageMemoryTotal{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorStorageMemoryUsed struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.storage_memory.used metric with initial data.
func (m *metricSparkExecutorStorageMemoryUsed) init() {
	m.data.SetName("spark.executor.storage_memory.used")
	m.data.SetDescription("Amount of memory currently used for storage.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkExecutorStorageMemoryUsed) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, locationAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("location", locationAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorStorageMemoryUsed) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorStorageMemoryUsed) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorStorageMemoryUsed(cfg MetricConfig) metricSparkExecutorStorageMemoryUsed {
	m := metricSparkExecutorStorageMemoryUsed{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorTasksActive struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.tasks.active metric with initial data.
func (m *metricSparkExecutorTasksActive) init() {
	m.data.SetName("spark.executor.tasks.active")
	m.data.SetDescription("Number of tasks currently running in this executor.")
	m.data.SetUnit("{ tasks }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkExecutorTasksActive) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorTasksActive) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorTasksActive) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorTasksActive(cfg MetricConfig) metricSparkExecutorTasksActive {
	m := metricSparkExecutorTasksActive{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorTasksMax struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.tasks.max metric with initial data.
func (m *metricSparkExecutorTasksMax) init() {
	m.data.SetName("spark.executor.tasks.max")
	m.data.SetDescription("Maximum number of tasks that can run concurrently in this executor.")
	m.data.SetUnit("{ tasks }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkExecutorTasksMax) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorTasksMax) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorTasksMax) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorTasksMax(cfg MetricConfig) metricSparkExecutorTasksMax {
	m := metricSparkExecutorTasksMax{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorTasksResults struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.tasks.results metric with initial data.
func (m *metricSparkExecutorTasksResults) init() {
	m.data.SetName("spark.executor.tasks.results")
	m.data.SetDescription("Number of tasks with a specific result in this executor.")
	m.data.SetUnit("{ tasks }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkExecutorTasksResults) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, executorTaskResultAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("executor_task_result", executorTaskResultAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorTasksResults) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorTasksResults) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorTasksResults(cfg MetricConfig) metricSparkExecutorTasksResults {
	m := metricSparkExecutorTasksResults{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkExecutorTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.executor.time metric with initial data.
func (m *metricSparkExecutorTime) init() {
	m.data.SetName("spark.executor.time")
	m.data.SetDescription("Elapsed time the JVM spent executing tasks in this executor.")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkExecutorTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkExecutorTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkExecutorTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkExecutorTime(cfg MetricConfig) metricSparkExecutorTime {
	m := metricSparkExecutorTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkHiveExternalCatalogFileCacheHits struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.hive_external_catalog.file_cache_hits metric with initial data.
func (m *metricSparkHiveExternalCatalogFileCacheHits) init() {
	m.data.SetName("spark.hive_external_catalog.file_cache_hits")
	m.data.SetDescription("Number of file cache hits on the HiveExternalCatalog.")
	m.data.SetUnit("{ hits }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkHiveExternalCatalogFileCacheHits) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkHiveExternalCatalogFileCacheHits) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkHiveExternalCatalogFileCacheHits) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkHiveExternalCatalogFileCacheHits(cfg MetricConfig) metricSparkHiveExternalCatalogFileCacheHits {
	m := metricSparkHiveExternalCatalogFileCacheHits{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkHiveExternalCatalogFilesDiscovered struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.hive_external_catalog.files_discovered metric with initial data.
func (m *metricSparkHiveExternalCatalogFilesDiscovered) init() {
	m.data.SetName("spark.hive_external_catalog.files_discovered")
	m.data.SetDescription("Number of files discovered while listing the partitions of a table in the Hive metastore")
	m.data.SetUnit("{ files }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkHiveExternalCatalogFilesDiscovered) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkHiveExternalCatalogFilesDiscovered) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkHiveExternalCatalogFilesDiscovered) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkHiveExternalCatalogFilesDiscovered(cfg MetricConfig) metricSparkHiveExternalCatalogFilesDiscovered {
	m := metricSparkHiveExternalCatalogFilesDiscovered{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkHiveExternalCatalogHiveClientCalls struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.hive_external_catalog.hive_client_calls metric with initial data.
func (m *metricSparkHiveExternalCatalogHiveClientCalls) init() {
	m.data.SetName("spark.hive_external_catalog.hive_client_calls")
	m.data.SetDescription("Number of calls to the underlying Hive Metastore client made by the Spark application.")
	m.data.SetUnit("{ calls }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkHiveExternalCatalogHiveClientCalls) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkHiveExternalCatalogHiveClientCalls) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkHiveExternalCatalogHiveClientCalls) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkHiveExternalCatalogHiveClientCalls(cfg MetricConfig) metricSparkHiveExternalCatalogHiveClientCalls {
	m := metricSparkHiveExternalCatalogHiveClientCalls{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkHiveExternalCatalogParallelListingJobs struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.hive_external_catalog.parallel_listing_jobs metric with initial data.
func (m *metricSparkHiveExternalCatalogParallelListingJobs) init() {
	m.data.SetName("spark.hive_external_catalog.parallel_listing_jobs")
	m.data.SetDescription("Number of parallel listing jobs initiated by the HiveExternalCatalog when listing partitions of a table.")
	m.data.SetUnit("{ listing_jobs }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkHiveExternalCatalogParallelListingJobs) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkHiveExternalCatalogParallelListingJobs) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkHiveExternalCatalogParallelListingJobs) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkHiveExternalCatalogParallelListingJobs(cfg MetricConfig) metricSparkHiveExternalCatalogParallelListingJobs {
	m := metricSparkHiveExternalCatalogParallelListingJobs{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkHiveExternalCatalogPartitionsFetched struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.hive_external_catalog.partitions_fetched metric with initial data.
func (m *metricSparkHiveExternalCatalogPartitionsFetched) init() {
	m.data.SetName("spark.hive_external_catalog.partitions_fetched")
	m.data.SetDescription("Table partitions fetched by the HiveExternalCatalog.")
	m.data.SetUnit("{ partitions }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkHiveExternalCatalogPartitionsFetched) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkHiveExternalCatalogPartitionsFetched) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkHiveExternalCatalogPartitionsFetched) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkHiveExternalCatalogPartitionsFetched(cfg MetricConfig) metricSparkHiveExternalCatalogPartitionsFetched {
	m := metricSparkHiveExternalCatalogPartitionsFetched{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkJobStagesActive struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.job.stages.active metric with initial data.
func (m *metricSparkJobStagesActive) init() {
	m.data.SetName("spark.job.stages.active")
	m.data.SetDescription("Number of active stages in this job.")
	m.data.SetUnit("{ tasks }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkJobStagesActive) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkJobStagesActive) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkJobStagesActive) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkJobStagesActive(cfg MetricConfig) metricSparkJobStagesActive {
	m := metricSparkJobStagesActive{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkJobStagesResults struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.job.stages.results metric with initial data.
func (m *metricSparkJobStagesResults) init() {
	m.data.SetName("spark.job.stages.results")
	m.data.SetDescription("Number of stages with a specific result in this job.")
	m.data.SetUnit("{ tasks }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkJobStagesResults) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, jobStageResultAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("job_stage_result", jobStageResultAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkJobStagesResults) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkJobStagesResults) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkJobStagesResults(cfg MetricConfig) metricSparkJobStagesResults {
	m := metricSparkJobStagesResults{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkJobTasksActive struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.job.tasks.active metric with initial data.
func (m *metricSparkJobTasksActive) init() {
	m.data.SetName("spark.job.tasks.active")
	m.data.SetDescription("Number of active tasks in this job.")
	m.data.SetUnit("{ tasks }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkJobTasksActive) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkJobTasksActive) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkJobTasksActive) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkJobTasksActive(cfg MetricConfig) metricSparkJobTasksActive {
	m := metricSparkJobTasksActive{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkJobTasksResults struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.job.tasks.results metric with initial data.
func (m *metricSparkJobTasksResults) init() {
	m.data.SetName("spark.job.tasks.results")
	m.data.SetDescription("Number of tasks with a specific result in this job.")
	m.data.SetUnit("{ tasks }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkJobTasksResults) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, jobTaskResultAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("job_task_result", jobTaskResultAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkJobTasksResults) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkJobTasksResults) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkJobTasksResults(cfg MetricConfig) metricSparkJobTasksResults {
	m := metricSparkJobTasksResults{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkJvmCPUTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.jvm_cpu_time metric with initial data.
func (m *metricSparkJvmCPUTime) init() {
	m.data.SetName("spark.jvm_cpu_time")
	m.data.SetDescription("Current CPU time taken by the Spark component.")
	m.data.SetUnit("ns")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkJvmCPUTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkJvmCPUTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkJvmCPUTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkJvmCPUTime(cfg MetricConfig) metricSparkJvmCPUTime {
	m := metricSparkJvmCPUTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkLiveListenerBusEventsDropped struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.live_listener_bus.events_dropped metric with initial data.
func (m *metricSparkLiveListenerBusEventsDropped) init() {
	m.data.SetName("spark.live_listener_bus.events_dropped")
	m.data.SetDescription("Number of events that have been dropped by the LiveListenerBus.")
	m.data.SetUnit("{ events }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkLiveListenerBusEventsDropped) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkLiveListenerBusEventsDropped) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkLiveListenerBusEventsDropped) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkLiveListenerBusEventsDropped(cfg MetricConfig) metricSparkLiveListenerBusEventsDropped {
	m := metricSparkLiveListenerBusEventsDropped{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkLiveListenerBusEventsPosted struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.live_listener_bus.events_posted metric with initial data.
func (m *metricSparkLiveListenerBusEventsPosted) init() {
	m.data.SetName("spark.live_listener_bus.events_posted")
	m.data.SetDescription("Number of events that have been posted on the LiveListenerBus.")
	m.data.SetUnit("{ events }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkLiveListenerBusEventsPosted) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkLiveListenerBusEventsPosted) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkLiveListenerBusEventsPosted) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkLiveListenerBusEventsPosted(cfg MetricConfig) metricSparkLiveListenerBusEventsPosted {
	m := metricSparkLiveListenerBusEventsPosted{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkLiveListenerBusProcessingTimeAverage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.live_listener_bus.processing_time.average metric with initial data.
func (m *metricSparkLiveListenerBusProcessingTimeAverage) init() {
	m.data.SetName("spark.live_listener_bus.processing_time.average")
	m.data.SetDescription("Average time taken for the LiveListenerBus to process an event posted to it.")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
}

func (m *metricSparkLiveListenerBusProcessingTimeAverage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkLiveListenerBusProcessingTimeAverage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkLiveListenerBusProcessingTimeAverage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkLiveListenerBusProcessingTimeAverage(cfg MetricConfig) metricSparkLiveListenerBusProcessingTimeAverage {
	m := metricSparkLiveListenerBusProcessingTimeAverage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkLiveListenerBusQueueSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.live_listener_bus.queue_size metric with initial data.
func (m *metricSparkLiveListenerBusQueueSize) init() {
	m.data.SetName("spark.live_listener_bus.queue_size")
	m.data.SetDescription("Number of events currently waiting to be processed by the LiveListenerBus.")
	m.data.SetUnit("{ events }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricSparkLiveListenerBusQueueSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkLiveListenerBusQueueSize) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkLiveListenerBusQueueSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkLiveListenerBusQueueSize(cfg MetricConfig) metricSparkLiveListenerBusQueueSize {
	m := metricSparkLiveListenerBusQueueSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageDiskSpilled struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.disk.spilled metric with initial data.
func (m *metricSparkStageDiskSpilled) init() {
	m.data.SetName("spark.stage.disk.spilled")
	m.data.SetDescription("The amount of disk space used for storing portions of overly large data chunks that couldn’t fit in memory in this stage.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageDiskSpilled) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageDiskSpilled) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageDiskSpilled) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageDiskSpilled(cfg MetricConfig) metricSparkStageDiskSpilled {
	m := metricSparkStageDiskSpilled{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageExecutorCPUTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.executor.cpu_time metric with initial data.
func (m *metricSparkStageExecutorCPUTime) init() {
	m.data.SetName("spark.stage.executor.cpu_time")
	m.data.SetDescription("CPU time spent by the executor in this stage.")
	m.data.SetUnit("ns")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageExecutorCPUTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageExecutorCPUTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageExecutorCPUTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageExecutorCPUTime(cfg MetricConfig) metricSparkStageExecutorCPUTime {
	m := metricSparkStageExecutorCPUTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageExecutorRunTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.executor.run_time metric with initial data.
func (m *metricSparkStageExecutorRunTime) init() {
	m.data.SetName("spark.stage.executor.run_time")
	m.data.SetDescription("Amount of time spent by the executor in this stage.")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageExecutorRunTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageExecutorRunTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageExecutorRunTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageExecutorRunTime(cfg MetricConfig) metricSparkStageExecutorRunTime {
	m := metricSparkStageExecutorRunTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageIoRecords struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.io.records metric with initial data.
func (m *metricSparkStageIoRecords) init() {
	m.data.SetName("spark.stage.io.records")
	m.data.SetDescription("Number of records written and read in this stage.")
	m.data.SetUnit("{ records }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageIoRecords) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageIoRecords) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageIoRecords) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageIoRecords(cfg MetricConfig) metricSparkStageIoRecords {
	m := metricSparkStageIoRecords{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageIoSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.io.size metric with initial data.
func (m *metricSparkStageIoSize) init() {
	m.data.SetName("spark.stage.io.size")
	m.data.SetDescription("Amount of data written and read at this stage.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageIoSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageIoSize) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageIoSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageIoSize(cfg MetricConfig) metricSparkStageIoSize {
	m := metricSparkStageIoSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageJvmGcTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.jvm_gc_time metric with initial data.
func (m *metricSparkStageJvmGcTime) init() {
	m.data.SetName("spark.stage.jvm_gc_time")
	m.data.SetDescription("The amount of time the JVM spent on garbage collection in this stage.")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageJvmGcTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageJvmGcTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageJvmGcTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageJvmGcTime(cfg MetricConfig) metricSparkStageJvmGcTime {
	m := metricSparkStageJvmGcTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageMemoryPeak struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.memory.peak metric with initial data.
func (m *metricSparkStageMemoryPeak) init() {
	m.data.SetName("spark.stage.memory.peak")
	m.data.SetDescription("Peak memory used by internal data structures created during shuffles, aggregations and joins in this stage.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageMemoryPeak) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageMemoryPeak) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageMemoryPeak) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageMemoryPeak(cfg MetricConfig) metricSparkStageMemoryPeak {
	m := metricSparkStageMemoryPeak{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageMemorySpilled struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.memory.spilled metric with initial data.
func (m *metricSparkStageMemorySpilled) init() {
	m.data.SetName("spark.stage.memory.spilled")
	m.data.SetDescription("The amount of memory moved to disk due to size constraints (spilled) in this stage.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageMemorySpilled) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageMemorySpilled) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageMemorySpilled) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageMemorySpilled(cfg MetricConfig) metricSparkStageMemorySpilled {
	m := metricSparkStageMemorySpilled{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageShuffleBlocksFetched struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.shuffle.blocks_fetched metric with initial data.
func (m *metricSparkStageShuffleBlocksFetched) init() {
	m.data.SetName("spark.stage.shuffle.blocks_fetched")
	m.data.SetDescription("Number of blocks fetched in shuffle operations in this stage.")
	m.data.SetUnit("{ blocks }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageShuffleBlocksFetched) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool, sourceAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
	dp.Attributes().PutStr("source", sourceAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageShuffleBlocksFetched) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageShuffleBlocksFetched) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageShuffleBlocksFetched(cfg MetricConfig) metricSparkStageShuffleBlocksFetched {
	m := metricSparkStageShuffleBlocksFetched{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageShuffleFetchWaitTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.shuffle.fetch_wait_time metric with initial data.
func (m *metricSparkStageShuffleFetchWaitTime) init() {
	m.data.SetName("spark.stage.shuffle.fetch_wait_time")
	m.data.SetDescription("Time spent in this stage waiting for remote shuffle blocks.")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageShuffleFetchWaitTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageShuffleFetchWaitTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageShuffleFetchWaitTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageShuffleFetchWaitTime(cfg MetricConfig) metricSparkStageShuffleFetchWaitTime {
	m := metricSparkStageShuffleFetchWaitTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageShuffleIoDisk struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.shuffle.io.disk metric with initial data.
func (m *metricSparkStageShuffleIoDisk) init() {
	m.data.SetName("spark.stage.shuffle.io.disk")
	m.data.SetDescription("Amount of data read to disk in shuffle operations (sometimes required for large blocks, as opposed to the default behavior of reading into memory).")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageShuffleIoDisk) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageShuffleIoDisk) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageShuffleIoDisk) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageShuffleIoDisk(cfg MetricConfig) metricSparkStageShuffleIoDisk {
	m := metricSparkStageShuffleIoDisk{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageShuffleIoRecords struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.shuffle.io.records metric with initial data.
func (m *metricSparkStageShuffleIoRecords) init() {
	m.data.SetName("spark.stage.shuffle.io.records")
	m.data.SetDescription("Number of records written or read in shuffle operations in this stage.")
	m.data.SetUnit("{ records }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageShuffleIoRecords) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageShuffleIoRecords) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageShuffleIoRecords) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageShuffleIoRecords(cfg MetricConfig) metricSparkStageShuffleIoRecords {
	m := metricSparkStageShuffleIoRecords{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageShuffleIoSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.shuffle.io.size metric with initial data.
func (m *metricSparkStageShuffleIoSize) init() {
	m.data.SetName("spark.stage.shuffle.io.size")
	m.data.SetDescription("Amount of data written or read in shuffle operations in this stage.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageShuffleIoSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool, sourceAttributeValue string, directionAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
	dp.Attributes().PutStr("source", sourceAttributeValue)
	dp.Attributes().PutStr("direction", directionAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageShuffleIoSize) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageShuffleIoSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageShuffleIoSize(cfg MetricConfig) metricSparkStageShuffleIoSize {
	m := metricSparkStageShuffleIoSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageShuffleWriteTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.shuffle.write_time metric with initial data.
func (m *metricSparkStageShuffleWriteTime) init() {
	m.data.SetName("spark.stage.shuffle.write_time")
	m.data.SetDescription("Time spent blocking on writes to disk or buffer cache in this stage.")
	m.data.SetUnit("ns")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageShuffleWriteTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageShuffleWriteTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageShuffleWriteTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageShuffleWriteTime(cfg MetricConfig) metricSparkStageShuffleWriteTime {
	m := metricSparkStageShuffleWriteTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageTaskActive struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.task.active metric with initial data.
func (m *metricSparkStageTaskActive) init() {
	m.data.SetName("spark.stage.task.active")
	m.data.SetDescription("Number of active tasks in this stage.")
	m.data.SetUnit("{ tasks }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageTaskActive) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageTaskActive) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageTaskActive) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageTaskActive(cfg MetricConfig) metricSparkStageTaskActive {
	m := metricSparkStageTaskActive{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageTaskResultSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.task.result_size metric with initial data.
func (m *metricSparkStageTaskResultSize) init() {
	m.data.SetName("spark.stage.task.result_size")
	m.data.SetDescription("The amount of data transmitted back to the driver by all the tasks in this stage.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageTaskResultSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageTaskResultSize) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageTaskResultSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageTaskResultSize(cfg MetricConfig) metricSparkStageTaskResultSize {
	m := metricSparkStageTaskResultSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricSparkStageTaskResults struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills spark.stage.task.results metric with initial data.
func (m *metricSparkStageTaskResults) init() {
	m.data.SetName("spark.stage.task.results")
	m.data.SetDescription("Number of tasks with a specific result in this stage.")
	m.data.SetUnit("{ tasks }")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricSparkStageTaskResults) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool, stageTaskResultAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("attempt_id", attemptIDAttributeValue)
	dp.Attributes().PutBool("stage_active", stageActiveAttributeValue)
	dp.Attributes().PutBool("stage_complete", stageCompleteAttributeValue)
	dp.Attributes().PutBool("stage_pending", stagePendingAttributeValue)
	dp.Attributes().PutBool("stage_failed", stageFailedAttributeValue)
	dp.Attributes().PutStr("stage_task_result", stageTaskResultAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricSparkStageTaskResults) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricSparkStageTaskResults) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricSparkStageTaskResults(cfg MetricConfig) metricSparkStageTaskResults {
	m := metricSparkStageTaskResults{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user config.
type MetricsBuilder struct {
	startTime                                          pcommon.Timestamp   // start time that will be applied to all recorded data points.
	metricsCapacity                                    int                 // maximum observed number of metrics per resource.
	resourceCapacity                                   int                 // maximum observed number of resource attributes.
	metricsBuffer                                      pmetric.Metrics     // accumulates metrics data before emitting.
	buildInfo                                          component.BuildInfo // contains version information
	resourceAttributesConfig                           ResourceAttributesConfig
	metricSparkBlockManagerDiskUsage                   metricSparkBlockManagerDiskUsage
	metricSparkBlockManagerMemoryRemaining             metricSparkBlockManagerMemoryRemaining
	metricSparkBlockManagerMemoryUsed                  metricSparkBlockManagerMemoryUsed
	metricSparkCodeGeneratorCompilationAverageTime     metricSparkCodeGeneratorCompilationAverageTime
	metricSparkCodeGeneratorCompilationCount           metricSparkCodeGeneratorCompilationCount
	metricSparkCodeGeneratorGeneratedClassAverageSize  metricSparkCodeGeneratorGeneratedClassAverageSize
	metricSparkCodeGeneratorGeneratedClassCount        metricSparkCodeGeneratorGeneratedClassCount
	metricSparkCodeGeneratorGeneratedMethodAverageSize metricSparkCodeGeneratorGeneratedMethodAverageSize
	metricSparkCodeGeneratorGeneratedMethodCount       metricSparkCodeGeneratorGeneratedMethodCount
	metricSparkCodeGeneratorSourceCodeAverageSize      metricSparkCodeGeneratorSourceCodeAverageSize
	metricSparkCodeGeneratorSourceCodeOperations       metricSparkCodeGeneratorSourceCodeOperations
	metricSparkDagSchedulerJobsActive                  metricSparkDagSchedulerJobsActive
	metricSparkDagSchedulerJobsCount                   metricSparkDagSchedulerJobsCount
	metricSparkDagSchedulerStages                      metricSparkDagSchedulerStages
	metricSparkDagSchedulerStagesFailed                metricSparkDagSchedulerStagesFailed
	metricSparkExecutorDiskUsage                       metricSparkExecutorDiskUsage
	metricSparkExecutorGcOperations                    metricSparkExecutorGcOperations
	metricSparkExecutorGcTime                          metricSparkExecutorGcTime
	metricSparkExecutorGcTime                          metricSparkExecutorGcTime
	metricSparkExecutorInputSize                       metricSparkExecutorInputSize
	metricSparkExecutorJvmMemory                       metricSparkExecutorJvmMemory
	metricSparkExecutorMemoryExecution                 metricSparkExecutorMemoryExecution
	metricSparkExecutorMemoryPool                      metricSparkExecutorMemoryPool
	metricSparkExecutorMemoryStorage                   metricSparkExecutorMemoryStorage
	metricSparkExecutorMemoryUsage                     metricSparkExecutorMemoryUsage
	metricSparkExecutorShuffleIoSize                   metricSparkExecutorShuffleIoSize
	metricSparkExecutorStorageMemoryTotal              metricSparkExecutorStorageMemoryTotal
	metricSparkExecutorStorageMemoryUsed               metricSparkExecutorStorageMemoryUsed
	metricSparkExecutorTasksActive                     metricSparkExecutorTasksActive
	metricSparkExecutorTasksMax                        metricSparkExecutorTasksMax
	metricSparkExecutorTasksResults                    metricSparkExecutorTasksResults
	metricSparkExecutorTime                            metricSparkExecutorTime
	metricSparkHiveExternalCatalogFileCacheHits        metricSparkHiveExternalCatalogFileCacheHits
	metricSparkHiveExternalCatalogFilesDiscovered      metricSparkHiveExternalCatalogFilesDiscovered
	metricSparkHiveExternalCatalogHiveClientCalls      metricSparkHiveExternalCatalogHiveClientCalls
	metricSparkHiveExternalCatalogParallelListingJobs  metricSparkHiveExternalCatalogParallelListingJobs
	metricSparkHiveExternalCatalogPartitionsFetched    metricSparkHiveExternalCatalogPartitionsFetched
	metricSparkJobStagesActive                         metricSparkJobStagesActive
	metricSparkJobStagesResults                        metricSparkJobStagesResults
	metricSparkJobTasksActive                          metricSparkJobTasksActive
	metricSparkJobTasksResults                         metricSparkJobTasksResults
	metricSparkJvmCPUTime                              metricSparkJvmCPUTime
	metricSparkLiveListenerBusEventsDropped            metricSparkLiveListenerBusEventsDropped
	metricSparkLiveListenerBusEventsPosted             metricSparkLiveListenerBusEventsPosted
	metricSparkLiveListenerBusProcessingTimeAverage    metricSparkLiveListenerBusProcessingTimeAverage
	metricSparkLiveListenerBusQueueSize                metricSparkLiveListenerBusQueueSize
	metricSparkStageDiskSpilled                        metricSparkStageDiskSpilled
	metricSparkStageExecutorCPUTime                    metricSparkStageExecutorCPUTime
	metricSparkStageExecutorRunTime                    metricSparkStageExecutorRunTime
	metricSparkStageIoRecords                          metricSparkStageIoRecords
	metricSparkStageIoSize                             metricSparkStageIoSize
	metricSparkStageJvmGcTime                          metricSparkStageJvmGcTime
	metricSparkStageMemoryPeak                         metricSparkStageMemoryPeak
	metricSparkStageMemorySpilled                      metricSparkStageMemorySpilled
	metricSparkStageShuffleBlocksFetched               metricSparkStageShuffleBlocksFetched
	metricSparkStageShuffleFetchWaitTime               metricSparkStageShuffleFetchWaitTime
	metricSparkStageShuffleIoDisk                      metricSparkStageShuffleIoDisk
	metricSparkStageShuffleIoRecords                   metricSparkStageShuffleIoRecords
	metricSparkStageShuffleIoSize                      metricSparkStageShuffleIoSize
	metricSparkStageShuffleWriteTime                   metricSparkStageShuffleWriteTime
	metricSparkStageTaskActive                         metricSparkStageTaskActive
	metricSparkStageTaskResultSize                     metricSparkStageTaskResultSize
	metricSparkStageTaskResults                        metricSparkStageTaskResults
}

// metricBuilderOption applies changes to default metrics builder.
type metricBuilderOption func(*MetricsBuilder)

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pcommon.Timestamp) metricBuilderOption {
	return func(mb *MetricsBuilder) {
		mb.startTime = startTime
	}
}

func NewMetricsBuilder(mbc MetricsBuilderConfig, settings receiver.CreateSettings, options ...metricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		startTime:                                          pcommon.NewTimestampFromTime(time.Now()),
		metricsBuffer:                                      pmetric.NewMetrics(),
		buildInfo:                                          settings.BuildInfo,
		resourceAttributesConfig:                           mbc.ResourceAttributes,
		metricSparkBlockManagerDiskUsage:                   newMetricSparkBlockManagerDiskUsage(mbc.Metrics.SparkBlockManagerDiskUsage),
		metricSparkBlockManagerMemoryRemaining:             newMetricSparkBlockManagerMemoryRemaining(mbc.Metrics.SparkBlockManagerMemoryRemaining),
		metricSparkBlockManagerMemoryUsed:                  newMetricSparkBlockManagerMemoryUsed(mbc.Metrics.SparkBlockManagerMemoryUsed),
		metricSparkCodeGeneratorCompilationAverageTime:     newMetricSparkCodeGeneratorCompilationAverageTime(mbc.Metrics.SparkCodeGeneratorCompilationAverageTime),
		metricSparkCodeGeneratorCompilationCount:           newMetricSparkCodeGeneratorCompilationCount(mbc.Metrics.SparkCodeGeneratorCompilationCount),
		metricSparkCodeGeneratorGeneratedClassAverageSize:  newMetricSparkCodeGeneratorGeneratedClassAverageSize(mbc.Metrics.SparkCodeGeneratorGeneratedClassAverageSize),
		metricSparkCodeGeneratorGeneratedClassCount:        newMetricSparkCodeGeneratorGeneratedClassCount(mbc.Metrics.SparkCodeGeneratorGeneratedClassCount),
		metricSparkCodeGeneratorGeneratedMethodAverageSize: newMetricSparkCodeGeneratorGeneratedMethodAverageSize(mbc.Metrics.SparkCodeGeneratorGeneratedMethodAverageSize),
		metricSparkCodeGeneratorGeneratedMethodCount:       newMetricSparkCodeGeneratorGeneratedMethodCount(mbc.Metrics.SparkCodeGeneratorGeneratedMethodCount),
		metricSparkCodeGeneratorSourceCodeAverageSize:      newMetricSparkCodeGeneratorSourceCodeAverageSize(mbc.Metrics.SparkCodeGeneratorSourceCodeAverageSize),
		metricSparkCodeGeneratorSourceCodeOperations:       newMetricSparkCodeGeneratorSourceCodeOperations(mbc.Metrics.SparkCodeGeneratorSourceCodeOperations),
		metricSparkDagSchedulerJobsActive:                  newMetricSparkDagSchedulerJobsActive(mbc.Metrics.SparkDagSchedulerJobsActive),
		metricSparkDagSchedulerJobsCount:                   newMetricSparkDagSchedulerJobsCount(mbc.Metrics.SparkDagSchedulerJobsCount),
		metricSparkDagSchedulerStages:                      newMetricSparkDagSchedulerStages(mbc.Metrics.SparkDagSchedulerStages),
		metricSparkDagSchedulerStagesFailed:                newMetricSparkDagSchedulerStagesFailed(mbc.Metrics.SparkDagSchedulerStagesFailed),
		metricSparkExecutorDiskUsage:                       newMetricSparkExecutorDiskUsage(mbc.Metrics.SparkExecutorDiskUsage),
		metricSparkExecutorGcOperations:                    newMetricSparkExecutorGcOperations(mbc.Metrics.SparkExecutorGcOperations),
		metricSparkExecutorGcTime:                          newMetricSparkExecutorGcTime(mbc.Metrics.SparkExecutorGcTime),
		metricSparkExecutorGcTime:                          newMetricSparkExecutorGcTime(mbc.Metrics.SparkExecutorGcTime),
		metricSparkExecutorInputSize:                       newMetricSparkExecutorInputSize(mbc.Metrics.SparkExecutorInputSize),
		metricSparkExecutorJvmMemory:                       newMetricSparkExecutorJvmMemory(mbc.Metrics.SparkExecutorJvmMemory),
		metricSparkExecutorMemoryExecution:                 newMetricSparkExecutorMemoryExecution(mbc.Metrics.SparkExecutorMemoryExecution),
		metricSparkExecutorMemoryPool:                      newMetricSparkExecutorMemoryPool(mbc.Metrics.SparkExecutorMemoryPool),
		metricSparkExecutorMemoryStorage:                   newMetricSparkExecutorMemoryStorage(mbc.Metrics.SparkExecutorMemoryStorage),
		metricSparkExecutorMemoryUsage:                     newMetricSparkExecutorMemoryUsage(mbc.Metrics.SparkExecutorMemoryUsage),
		metricSparkExecutorShuffleIoSize:                   newMetricSparkExecutorShuffleIoSize(mbc.Metrics.SparkExecutorShuffleIoSize),
		metricSparkExecutorStorageMemoryTotal:              newMetricSparkExecutorStorageMemoryTotal(mbc.Metrics.SparkExecutorStorageMemoryTotal),
		metricSparkExecutorStorageMemoryUsed:               newMetricSparkExecutorStorageMemoryUsed(mbc.Metrics.SparkExecutorStorageMemoryUsed),
		metricSparkExecutorTasksActive:                     newMetricSparkExecutorTasksActive(mbc.Metrics.SparkExecutorTasksActive),
		metricSparkExecutorTasksMax:                        newMetricSparkExecutorTasksMax(mbc.Metrics.SparkExecutorTasksMax),
		metricSparkExecutorTasksResults:                    newMetricSparkExecutorTasksResults(mbc.Metrics.SparkExecutorTasksResults),
		metricSparkExecutorTime:                            newMetricSparkExecutorTime(mbc.Metrics.SparkExecutorTime),
		metricSparkHiveExternalCatalogFileCacheHits:        newMetricSparkHiveExternalCatalogFileCacheHits(mbc.Metrics.SparkHiveExternalCatalogFileCacheHits),
		metricSparkHiveExternalCatalogFilesDiscovered:      newMetricSparkHiveExternalCatalogFilesDiscovered(mbc.Metrics.SparkHiveExternalCatalogFilesDiscovered),
		metricSparkHiveExternalCatalogHiveClientCalls:      newMetricSparkHiveExternalCatalogHiveClientCalls(mbc.Metrics.SparkHiveExternalCatalogHiveClientCalls),
		metricSparkHiveExternalCatalogParallelListingJobs:  newMetricSparkHiveExternalCatalogParallelListingJobs(mbc.Metrics.SparkHiveExternalCatalogParallelListingJobs),
		metricSparkHiveExternalCatalogPartitionsFetched:    newMetricSparkHiveExternalCatalogPartitionsFetched(mbc.Metrics.SparkHiveExternalCatalogPartitionsFetched),
		metricSparkJobStagesActive:                         newMetricSparkJobStagesActive(mbc.Metrics.SparkJobStagesActive),
		metricSparkJobStagesResults:                        newMetricSparkJobStagesResults(mbc.Metrics.SparkJobStagesResults),
		metricSparkJobTasksActive:                          newMetricSparkJobTasksActive(mbc.Metrics.SparkJobTasksActive),
		metricSparkJobTasksResults:                         newMetricSparkJobTasksResults(mbc.Metrics.SparkJobTasksResults),
		metricSparkJvmCPUTime:                              newMetricSparkJvmCPUTime(mbc.Metrics.SparkJvmCPUTime),
		metricSparkLiveListenerBusEventsDropped:            newMetricSparkLiveListenerBusEventsDropped(mbc.Metrics.SparkLiveListenerBusEventsDropped),
		metricSparkLiveListenerBusEventsPosted:             newMetricSparkLiveListenerBusEventsPosted(mbc.Metrics.SparkLiveListenerBusEventsPosted),
		metricSparkLiveListenerBusProcessingTimeAverage:    newMetricSparkLiveListenerBusProcessingTimeAverage(mbc.Metrics.SparkLiveListenerBusProcessingTimeAverage),
		metricSparkLiveListenerBusQueueSize:                newMetricSparkLiveListenerBusQueueSize(mbc.Metrics.SparkLiveListenerBusQueueSize),
		metricSparkStageDiskSpilled:                        newMetricSparkStageDiskSpilled(mbc.Metrics.SparkStageDiskSpilled),
		metricSparkStageExecutorCPUTime:                    newMetricSparkStageExecutorCPUTime(mbc.Metrics.SparkStageExecutorCPUTime),
		metricSparkStageExecutorRunTime:                    newMetricSparkStageExecutorRunTime(mbc.Metrics.SparkStageExecutorRunTime),
		metricSparkStageIoRecords:                          newMetricSparkStageIoRecords(mbc.Metrics.SparkStageIoRecords),
		metricSparkStageIoSize:                             newMetricSparkStageIoSize(mbc.Metrics.SparkStageIoSize),
		metricSparkStageJvmGcTime:                          newMetricSparkStageJvmGcTime(mbc.Metrics.SparkStageJvmGcTime),
		metricSparkStageMemoryPeak:                         newMetricSparkStageMemoryPeak(mbc.Metrics.SparkStageMemoryPeak),
		metricSparkStageMemorySpilled:                      newMetricSparkStageMemorySpilled(mbc.Metrics.SparkStageMemorySpilled),
		metricSparkStageShuffleBlocksFetched:               newMetricSparkStageShuffleBlocksFetched(mbc.Metrics.SparkStageShuffleBlocksFetched),
		metricSparkStageShuffleFetchWaitTime:               newMetricSparkStageShuffleFetchWaitTime(mbc.Metrics.SparkStageShuffleFetchWaitTime),
		metricSparkStageShuffleIoDisk:                      newMetricSparkStageShuffleIoDisk(mbc.Metrics.SparkStageShuffleIoDisk),
		metricSparkStageShuffleIoRecords:                   newMetricSparkStageShuffleIoRecords(mbc.Metrics.SparkStageShuffleIoRecords),
		metricSparkStageShuffleIoSize:                      newMetricSparkStageShuffleIoSize(mbc.Metrics.SparkStageShuffleIoSize),
		metricSparkStageShuffleWriteTime:                   newMetricSparkStageShuffleWriteTime(mbc.Metrics.SparkStageShuffleWriteTime),
		metricSparkStageTaskActive:                         newMetricSparkStageTaskActive(mbc.Metrics.SparkStageTaskActive),
		metricSparkStageTaskResultSize:                     newMetricSparkStageTaskResultSize(mbc.Metrics.SparkStageTaskResultSize),
		metricSparkStageTaskResults:                        newMetricSparkStageTaskResults(mbc.Metrics.SparkStageTaskResults),
	}
	for _, op := range options {
		op(mb)
	}
	return mb
}

// updateCapacity updates max length of metrics and resource attributes that will be used for the slice capacity.
func (mb *MetricsBuilder) updateCapacity(rm pmetric.ResourceMetrics) {
	if mb.metricsCapacity < rm.ScopeMetrics().At(0).Metrics().Len() {
		mb.metricsCapacity = rm.ScopeMetrics().At(0).Metrics().Len()
	}
	if mb.resourceCapacity < rm.Resource().Attributes().Len() {
		mb.resourceCapacity = rm.Resource().Attributes().Len()
	}
}

// ResourceMetricsOption applies changes to provided resource metrics.
type ResourceMetricsOption func(ResourceAttributesConfig, pmetric.ResourceMetrics)

// WithSparkApplicationID sets provided value as "spark.application.id" attribute for current resource.
func WithSparkApplicationID(val string) ResourceMetricsOption {
	return func(rac ResourceAttributesConfig, rm pmetric.ResourceMetrics) {
		if rac.SparkApplicationID.Enabled {
			rm.Resource().Attributes().PutStr("spark.application.id", val)
		}
	}
}

// WithSparkApplicationName sets provided value as "spark.application.name" attribute for current resource.
func WithSparkApplicationName(val string) ResourceMetricsOption {
	return func(rac ResourceAttributesConfig, rm pmetric.ResourceMetrics) {
		if rac.SparkApplicationName.Enabled {
			rm.Resource().Attributes().PutStr("spark.application.name", val)
		}
	}
}

// WithSparkComponentType sets provided value as "spark.component.type" attribute for current resource.
func WithSparkComponentType(val string) ResourceMetricsOption {
	return func(rac ResourceAttributesConfig, rm pmetric.ResourceMetrics) {
		if rac.SparkComponentType.Enabled {
			rm.Resource().Attributes().PutStr("spark.component.type", val)
		}
	}
}

// WithSparkExecutorID sets provided value as "spark.executor.id" attribute for current resource.
func WithSparkExecutorID(val string) ResourceMetricsOption {
	return func(rac ResourceAttributesConfig, rm pmetric.ResourceMetrics) {
		if rac.SparkExecutorID.Enabled {
			rm.Resource().Attributes().PutStr("spark.executor.id", val)
		}
	}
}

// WithSparkJobID sets provided value as "spark.job.id" attribute for current resource.
func WithSparkJobID(val int64) ResourceMetricsOption {
	return func(rac ResourceAttributesConfig, rm pmetric.ResourceMetrics) {
		if rac.SparkJobID.Enabled {
			rm.Resource().Attributes().PutInt("spark.job.id", val)
		}
	}
}

// WithSparkStageID sets provided value as "spark.stage.id" attribute for current resource.
func WithSparkStageID(val int64) ResourceMetricsOption {
	return func(rac ResourceAttributesConfig, rm pmetric.ResourceMetrics) {
		if rac.SparkStageID.Enabled {
			rm.Resource().Attributes().PutInt("spark.stage.id", val)
		}
	}
}

// WithStartTimeOverride overrides start time for all the resource metrics data points.
// This option should be only used if different start time has to be set on metrics coming from different resources.
func WithStartTimeOverride(start pcommon.Timestamp) ResourceMetricsOption {
	return func(_ ResourceAttributesConfig, rm pmetric.ResourceMetrics) {
		var dps pmetric.NumberDataPointSlice
		metrics := rm.ScopeMetrics().At(0).Metrics()
		for i := 0; i < metrics.Len(); i++ {
			switch metrics.At(i).Type() {
			case pmetric.MetricTypeGauge:
				dps = metrics.At(i).Gauge().DataPoints()
			case pmetric.MetricTypeSum:
				dps = metrics.At(i).Sum().DataPoints()
			}
			for j := 0; j < dps.Len(); j++ {
				dps.At(j).SetStartTimestamp(start)
			}
		}
	}
}

// EmitForResource saves all the generated metrics under a new resource and updates the internal state to be ready for
// recording another set of data points as part of another resource. This function can be helpful when one scraper
// needs to emit metrics from several resources. Otherwise calling this function is not required,
// just `Emit` function can be called instead.
// Resource attributes should be provided as ResourceMetricsOption arguments.
func (mb *MetricsBuilder) EmitForResource(rmo ...ResourceMetricsOption) {
	rm := pmetric.NewResourceMetrics()
	rm.Resource().Attributes().EnsureCapacity(mb.resourceCapacity)
	ils := rm.ScopeMetrics().AppendEmpty()
	ils.Scope().SetName("otelcol/apachesparkreceiver")
	ils.Scope().SetVersion(mb.buildInfo.Version)
	ils.Metrics().EnsureCapacity(mb.metricsCapacity)
	mb.metricSparkBlockManagerDiskUsage.emit(ils.Metrics())
	mb.metricSparkBlockManagerMemoryRemaining.emit(ils.Metrics())
	mb.metricSparkBlockManagerMemoryUsed.emit(ils.Metrics())
	mb.metricSparkCodeGeneratorCompilationAverageTime.emit(ils.Metrics())
	mb.metricSparkCodeGeneratorCompilationCount.emit(ils.Metrics())
	mb.metricSparkCodeGeneratorGeneratedClassAverageSize.emit(ils.Metrics())
	mb.metricSparkCodeGeneratorGeneratedClassCount.emit(ils.Metrics())
	mb.metricSparkCodeGeneratorGeneratedMethodAverageSize.emit(ils.Metrics())
	mb.metricSparkCodeGeneratorGeneratedMethodCount.emit(ils.Metrics())
	mb.metricSparkCodeGeneratorSourceCodeAverageSize.emit(ils.Metrics())
	mb.metricSparkCodeGeneratorSourceCodeOperations.emit(ils.Metrics())
	mb.metricSparkDagSchedulerJobsActive.emit(ils.Metrics())
	mb.metricSparkDagSchedulerJobsCount.emit(ils.Metrics())
	mb.metricSparkDagSchedulerStages.emit(ils.Metrics())
	mb.metricSparkDagSchedulerStagesFailed.emit(ils.Metrics())
	mb.metricSparkExecutorDiskUsage.emit(ils.Metrics())
	mb.metricSparkExecutorGcOperations.emit(ils.Metrics())
	mb.metricSparkExecutorGcTime.emit(ils.Metrics())
	mb.metricSparkExecutorGcTime.emit(ils.Metrics())
	mb.metricSparkExecutorInputSize.emit(ils.Metrics())
	mb.metricSparkExecutorJvmMemory.emit(ils.Metrics())
	mb.metricSparkExecutorMemoryExecution.emit(ils.Metrics())
	mb.metricSparkExecutorMemoryPool.emit(ils.Metrics())
	mb.metricSparkExecutorMemoryStorage.emit(ils.Metrics())
	mb.metricSparkExecutorMemoryUsage.emit(ils.Metrics())
	mb.metricSparkExecutorShuffleIoSize.emit(ils.Metrics())
	mb.metricSparkExecutorStorageMemoryTotal.emit(ils.Metrics())
	mb.metricSparkExecutorStorageMemoryUsed.emit(ils.Metrics())
	mb.metricSparkExecutorTasksActive.emit(ils.Metrics())
	mb.metricSparkExecutorTasksMax.emit(ils.Metrics())
	mb.metricSparkExecutorTasksResults.emit(ils.Metrics())
	mb.metricSparkExecutorTime.emit(ils.Metrics())
	mb.metricSparkHiveExternalCatalogFileCacheHits.emit(ils.Metrics())
	mb.metricSparkHiveExternalCatalogFilesDiscovered.emit(ils.Metrics())
	mb.metricSparkHiveExternalCatalogHiveClientCalls.emit(ils.Metrics())
	mb.metricSparkHiveExternalCatalogParallelListingJobs.emit(ils.Metrics())
	mb.metricSparkHiveExternalCatalogPartitionsFetched.emit(ils.Metrics())
	mb.metricSparkJobStagesActive.emit(ils.Metrics())
	mb.metricSparkJobStagesResults.emit(ils.Metrics())
	mb.metricSparkJobTasksActive.emit(ils.Metrics())
	mb.metricSparkJobTasksResults.emit(ils.Metrics())
	mb.metricSparkJvmCPUTime.emit(ils.Metrics())
	mb.metricSparkLiveListenerBusEventsDropped.emit(ils.Metrics())
	mb.metricSparkLiveListenerBusEventsPosted.emit(ils.Metrics())
	mb.metricSparkLiveListenerBusProcessingTimeAverage.emit(ils.Metrics())
	mb.metricSparkLiveListenerBusQueueSize.emit(ils.Metrics())
	mb.metricSparkStageDiskSpilled.emit(ils.Metrics())
	mb.metricSparkStageExecutorCPUTime.emit(ils.Metrics())
	mb.metricSparkStageExecutorRunTime.emit(ils.Metrics())
	mb.metricSparkStageIoRecords.emit(ils.Metrics())
	mb.metricSparkStageIoSize.emit(ils.Metrics())
	mb.metricSparkStageJvmGcTime.emit(ils.Metrics())
	mb.metricSparkStageMemoryPeak.emit(ils.Metrics())
	mb.metricSparkStageMemorySpilled.emit(ils.Metrics())
	mb.metricSparkStageShuffleBlocksFetched.emit(ils.Metrics())
	mb.metricSparkStageShuffleFetchWaitTime.emit(ils.Metrics())
	mb.metricSparkStageShuffleIoDisk.emit(ils.Metrics())
	mb.metricSparkStageShuffleIoRecords.emit(ils.Metrics())
	mb.metricSparkStageShuffleIoSize.emit(ils.Metrics())
	mb.metricSparkStageShuffleWriteTime.emit(ils.Metrics())
	mb.metricSparkStageTaskActive.emit(ils.Metrics())
	mb.metricSparkStageTaskResultSize.emit(ils.Metrics())
	mb.metricSparkStageTaskResults.emit(ils.Metrics())

	for _, op := range rmo {
		op(mb.resourceAttributesConfig, rm)
	}
	if ils.Metrics().Len() > 0 {
		mb.updateCapacity(rm)
		rm.MoveTo(mb.metricsBuffer.ResourceMetrics().AppendEmpty())
	}
}

// Emit returns all the metrics accumulated by the metrics builder and updates the internal state to be ready for
// recording another set of metrics. This function will be responsible for applying all the transformations required to
// produce metric representation defined in metadata and user config, e.g. delta or cumulative.
func (mb *MetricsBuilder) Emit(rmo ...ResourceMetricsOption) pmetric.Metrics {
	mb.EmitForResource(rmo...)
	metrics := mb.metricsBuffer
	mb.metricsBuffer = pmetric.NewMetrics()
	return metrics
}

// RecordSparkBlockManagerDiskUsageDataPoint adds a data point to spark.block_manager.disk.usage metric.
func (mb *MetricsBuilder) RecordSparkBlockManagerDiskUsageDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkBlockManagerDiskUsage.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkBlockManagerMemoryRemainingDataPoint adds a data point to spark.block_manager.memory.remaining metric.
func (mb *MetricsBuilder) RecordSparkBlockManagerMemoryRemainingDataPoint(ts pcommon.Timestamp, val int64, locationAttributeValue AttributeLocation) {
	mb.metricSparkBlockManagerMemoryRemaining.recordDataPoint(mb.startTime, ts, val, locationAttributeValue.String())
}

// RecordSparkBlockManagerMemoryUsedDataPoint adds a data point to spark.block_manager.memory.used metric.
func (mb *MetricsBuilder) RecordSparkBlockManagerMemoryUsedDataPoint(ts pcommon.Timestamp, val int64, locationAttributeValue AttributeLocation) {
	mb.metricSparkBlockManagerMemoryUsed.recordDataPoint(mb.startTime, ts, val, locationAttributeValue.String())
}

// RecordSparkCodeGeneratorCompilationAverageTimeDataPoint adds a data point to spark.code_generator.compilation.average_time metric.
func (mb *MetricsBuilder) RecordSparkCodeGeneratorCompilationAverageTimeDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSparkCodeGeneratorCompilationAverageTime.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkCodeGeneratorCompilationCountDataPoint adds a data point to spark.code_generator.compilation.count metric.
func (mb *MetricsBuilder) RecordSparkCodeGeneratorCompilationCountDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkCodeGeneratorCompilationCount.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkCodeGeneratorGeneratedClassAverageSizeDataPoint adds a data point to spark.code_generator.generated_class.average_size metric.
func (mb *MetricsBuilder) RecordSparkCodeGeneratorGeneratedClassAverageSizeDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSparkCodeGeneratorGeneratedClassAverageSize.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkCodeGeneratorGeneratedClassCountDataPoint adds a data point to spark.code_generator.generated_class.count metric.
func (mb *MetricsBuilder) RecordSparkCodeGeneratorGeneratedClassCountDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkCodeGeneratorGeneratedClassCount.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkCodeGeneratorGeneratedMethodAverageSizeDataPoint adds a data point to spark.code_generator.generated_method.average_size metric.
func (mb *MetricsBuilder) RecordSparkCodeGeneratorGeneratedMethodAverageSizeDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSparkCodeGeneratorGeneratedMethodAverageSize.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkCodeGeneratorGeneratedMethodCountDataPoint adds a data point to spark.code_generator.generated_method.count metric.
func (mb *MetricsBuilder) RecordSparkCodeGeneratorGeneratedMethodCountDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkCodeGeneratorGeneratedMethodCount.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkCodeGeneratorSourceCodeAverageSizeDataPoint adds a data point to spark.code_generator.source_code.average_size metric.
func (mb *MetricsBuilder) RecordSparkCodeGeneratorSourceCodeAverageSizeDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSparkCodeGeneratorSourceCodeAverageSize.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkCodeGeneratorSourceCodeOperationsDataPoint adds a data point to spark.code_generator.source_code.operations metric.
func (mb *MetricsBuilder) RecordSparkCodeGeneratorSourceCodeOperationsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkCodeGeneratorSourceCodeOperations.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkDagSchedulerJobsActiveDataPoint adds a data point to spark.dag_scheduler.jobs.active metric.
func (mb *MetricsBuilder) RecordSparkDagSchedulerJobsActiveDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkDagSchedulerJobsActive.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkDagSchedulerJobsCountDataPoint adds a data point to spark.dag_scheduler.jobs.count metric.
func (mb *MetricsBuilder) RecordSparkDagSchedulerJobsCountDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkDagSchedulerJobsCount.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkDagSchedulerStagesDataPoint adds a data point to spark.dag_scheduler.stages metric.
func (mb *MetricsBuilder) RecordSparkDagSchedulerStagesDataPoint(ts pcommon.Timestamp, val int64, schedulerWaitingAttributeValue bool, schedulerRunningAttributeValue bool) {
	mb.metricSparkDagSchedulerStages.recordDataPoint(mb.startTime, ts, val, schedulerWaitingAttributeValue, schedulerRunningAttributeValue)
}

// RecordSparkDagSchedulerStagesFailedDataPoint adds a data point to spark.dag_scheduler.stages.failed metric.
func (mb *MetricsBuilder) RecordSparkDagSchedulerStagesFailedDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkDagSchedulerStagesFailed.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkExecutorDiskUsageDataPoint adds a data point to spark.executor.disk.usage metric.
func (mb *MetricsBuilder) RecordSparkExecutorDiskUsageDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkExecutorDiskUsage.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkExecutorGcOperationsDataPoint adds a data point to spark.executor.gc.operations metric.
func (mb *MetricsBuilder) RecordSparkExecutorGcOperationsDataPoint(ts pcommon.Timestamp, val int64, gcTypeAttributeValue AttributeGcType) {
	mb.metricSparkExecutorGcOperations.recordDataPoint(mb.startTime, ts, val, gcTypeAttributeValue.String())
}

// RecordSparkExecutorGcTimeDataPoint adds a data point to spark.executor.gc.time metric.
func (mb *MetricsBuilder) RecordSparkExecutorGcTimeDataPoint(ts pcommon.Timestamp, val int64, gcTypeAttributeValue AttributeGcType) {
	mb.metricSparkExecutorGcTime.recordDataPoint(mb.startTime, ts, val, gcTypeAttributeValue.String())
}

// RecordSparkExecutorGcTimeDataPoint adds a data point to spark.executor.gc_time metric.
func (mb *MetricsBuilder) RecordSparkExecutorGcTimeDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkExecutorGcTime.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkExecutorInputSizeDataPoint adds a data point to spark.executor.input_size metric.
func (mb *MetricsBuilder) RecordSparkExecutorInputSizeDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkExecutorInputSize.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkExecutorJvmMemoryDataPoint adds a data point to spark.executor.jvm_memory metric.
func (mb *MetricsBuilder) RecordSparkExecutorJvmMemoryDataPoint(ts pcommon.Timestamp, val int64, locationAttributeValue AttributeLocation) {
	mb.metricSparkExecutorJvmMemory.recordDataPoint(mb.startTime, ts, val, locationAttributeValue.String())
}

// RecordSparkExecutorMemoryExecutionDataPoint adds a data point to spark.executor.memory.execution metric.
func (mb *MetricsBuilder) RecordSparkExecutorMemoryExecutionDataPoint(ts pcommon.Timestamp, val int64, locationAttributeValue AttributeLocation) {
	mb.metricSparkExecutorMemoryExecution.recordDataPoint(mb.startTime, ts, val, locationAttributeValue.String())
}

// RecordSparkExecutorMemoryPoolDataPoint adds a data point to spark.executor.memory.pool metric.
func (mb *MetricsBuilder) RecordSparkExecutorMemoryPoolDataPoint(ts pcommon.Timestamp, val int64, poolMemoryTypeAttributeValue AttributePoolMemoryType) {
	mb.metricSparkExecutorMemoryPool.recordDataPoint(mb.startTime, ts, val, poolMemoryTypeAttributeValue.String())
}

// RecordSparkExecutorMemoryStorageDataPoint adds a data point to spark.executor.memory.storage metric.
func (mb *MetricsBuilder) RecordSparkExecutorMemoryStorageDataPoint(ts pcommon.Timestamp, val int64, locationAttributeValue AttributeLocation) {
	mb.metricSparkExecutorMemoryStorage.recordDataPoint(mb.startTime, ts, val, locationAttributeValue.String())
}

// RecordSparkExecutorMemoryUsageDataPoint adds a data point to spark.executor.memory.usage metric.
func (mb *MetricsBuilder) RecordSparkExecutorMemoryUsageDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkExecutorMemoryUsage.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkExecutorShuffleIoSizeDataPoint adds a data point to spark.executor.shuffle.io.size metric.
func (mb *MetricsBuilder) RecordSparkExecutorShuffleIoSizeDataPoint(ts pcommon.Timestamp, val int64, directionAttributeValue AttributeDirection) {
	mb.metricSparkExecutorShuffleIoSize.recordDataPoint(mb.startTime, ts, val, directionAttributeValue.String())
}

// RecordSparkExecutorStorageMemoryTotalDataPoint adds a data point to spark.executor.storage_memory.total metric.
func (mb *MetricsBuilder) RecordSparkExecutorStorageMemoryTotalDataPoint(ts pcommon.Timestamp, val int64, locationAttributeValue AttributeLocation) {
	mb.metricSparkExecutorStorageMemoryTotal.recordDataPoint(mb.startTime, ts, val, locationAttributeValue.String())
}

// RecordSparkExecutorStorageMemoryUsedDataPoint adds a data point to spark.executor.storage_memory.used metric.
func (mb *MetricsBuilder) RecordSparkExecutorStorageMemoryUsedDataPoint(ts pcommon.Timestamp, val int64, locationAttributeValue AttributeLocation) {
	mb.metricSparkExecutorStorageMemoryUsed.recordDataPoint(mb.startTime, ts, val, locationAttributeValue.String())
}

// RecordSparkExecutorTasksActiveDataPoint adds a data point to spark.executor.tasks.active metric.
func (mb *MetricsBuilder) RecordSparkExecutorTasksActiveDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkExecutorTasksActive.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkExecutorTasksMaxDataPoint adds a data point to spark.executor.tasks.max metric.
func (mb *MetricsBuilder) RecordSparkExecutorTasksMaxDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkExecutorTasksMax.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkExecutorTasksResultsDataPoint adds a data point to spark.executor.tasks.results metric.
func (mb *MetricsBuilder) RecordSparkExecutorTasksResultsDataPoint(ts pcommon.Timestamp, val int64, executorTaskResultAttributeValue AttributeExecutorTaskResult) {
	mb.metricSparkExecutorTasksResults.recordDataPoint(mb.startTime, ts, val, executorTaskResultAttributeValue.String())
}

// RecordSparkExecutorTimeDataPoint adds a data point to spark.executor.time metric.
func (mb *MetricsBuilder) RecordSparkExecutorTimeDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkExecutorTime.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkHiveExternalCatalogFileCacheHitsDataPoint adds a data point to spark.hive_external_catalog.file_cache_hits metric.
func (mb *MetricsBuilder) RecordSparkHiveExternalCatalogFileCacheHitsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkHiveExternalCatalogFileCacheHits.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkHiveExternalCatalogFilesDiscoveredDataPoint adds a data point to spark.hive_external_catalog.files_discovered metric.
func (mb *MetricsBuilder) RecordSparkHiveExternalCatalogFilesDiscoveredDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkHiveExternalCatalogFilesDiscovered.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkHiveExternalCatalogHiveClientCallsDataPoint adds a data point to spark.hive_external_catalog.hive_client_calls metric.
func (mb *MetricsBuilder) RecordSparkHiveExternalCatalogHiveClientCallsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkHiveExternalCatalogHiveClientCalls.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkHiveExternalCatalogParallelListingJobsDataPoint adds a data point to spark.hive_external_catalog.parallel_listing_jobs metric.
func (mb *MetricsBuilder) RecordSparkHiveExternalCatalogParallelListingJobsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkHiveExternalCatalogParallelListingJobs.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkHiveExternalCatalogPartitionsFetchedDataPoint adds a data point to spark.hive_external_catalog.partitions_fetched metric.
func (mb *MetricsBuilder) RecordSparkHiveExternalCatalogPartitionsFetchedDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkHiveExternalCatalogPartitionsFetched.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkJobStagesActiveDataPoint adds a data point to spark.job.stages.active metric.
func (mb *MetricsBuilder) RecordSparkJobStagesActiveDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkJobStagesActive.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkJobStagesResultsDataPoint adds a data point to spark.job.stages.results metric.
func (mb *MetricsBuilder) RecordSparkJobStagesResultsDataPoint(ts pcommon.Timestamp, val int64, jobStageResultAttributeValue AttributeJobStageResult) {
	mb.metricSparkJobStagesResults.recordDataPoint(mb.startTime, ts, val, jobStageResultAttributeValue.String())
}

// RecordSparkJobTasksActiveDataPoint adds a data point to spark.job.tasks.active metric.
func (mb *MetricsBuilder) RecordSparkJobTasksActiveDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkJobTasksActive.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkJobTasksResultsDataPoint adds a data point to spark.job.tasks.results metric.
func (mb *MetricsBuilder) RecordSparkJobTasksResultsDataPoint(ts pcommon.Timestamp, val int64, jobTaskResultAttributeValue AttributeJobTaskResult) {
	mb.metricSparkJobTasksResults.recordDataPoint(mb.startTime, ts, val, jobTaskResultAttributeValue.String())
}

// RecordSparkJvmCPUTimeDataPoint adds a data point to spark.jvm_cpu_time metric.
func (mb *MetricsBuilder) RecordSparkJvmCPUTimeDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkJvmCPUTime.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkLiveListenerBusEventsDroppedDataPoint adds a data point to spark.live_listener_bus.events_dropped metric.
func (mb *MetricsBuilder) RecordSparkLiveListenerBusEventsDroppedDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkLiveListenerBusEventsDropped.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkLiveListenerBusEventsPostedDataPoint adds a data point to spark.live_listener_bus.events_posted metric.
func (mb *MetricsBuilder) RecordSparkLiveListenerBusEventsPostedDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkLiveListenerBusEventsPosted.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkLiveListenerBusProcessingTimeAverageDataPoint adds a data point to spark.live_listener_bus.processing_time.average metric.
func (mb *MetricsBuilder) RecordSparkLiveListenerBusProcessingTimeAverageDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricSparkLiveListenerBusProcessingTimeAverage.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkLiveListenerBusQueueSizeDataPoint adds a data point to spark.live_listener_bus.queue_size metric.
func (mb *MetricsBuilder) RecordSparkLiveListenerBusQueueSizeDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricSparkLiveListenerBusQueueSize.recordDataPoint(mb.startTime, ts, val)
}

// RecordSparkStageDiskSpilledDataPoint adds a data point to spark.stage.disk.spilled metric.
func (mb *MetricsBuilder) RecordSparkStageDiskSpilledDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	mb.metricSparkStageDiskSpilled.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue)
}

// RecordSparkStageExecutorCPUTimeDataPoint adds a data point to spark.stage.executor.cpu_time metric.
func (mb *MetricsBuilder) RecordSparkStageExecutorCPUTimeDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	mb.metricSparkStageExecutorCPUTime.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue)
}

// RecordSparkStageExecutorRunTimeDataPoint adds a data point to spark.stage.executor.run_time metric.
func (mb *MetricsBuilder) RecordSparkStageExecutorRunTimeDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	mb.metricSparkStageExecutorRunTime.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue)
}

// RecordSparkStageIoRecordsDataPoint adds a data point to spark.stage.io.records metric.
func (mb *MetricsBuilder) RecordSparkStageIoRecordsDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool, directionAttributeValue AttributeDirection) {
	mb.metricSparkStageIoRecords.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue, directionAttributeValue.String())
}

// RecordSparkStageIoSizeDataPoint adds a data point to spark.stage.io.size metric.
func (mb *MetricsBuilder) RecordSparkStageIoSizeDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool, directionAttributeValue AttributeDirection) {
	mb.metricSparkStageIoSize.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue, directionAttributeValue.String())
}

// RecordSparkStageJvmGcTimeDataPoint adds a data point to spark.stage.jvm_gc_time metric.
func (mb *MetricsBuilder) RecordSparkStageJvmGcTimeDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	mb.metricSparkStageJvmGcTime.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue)
}

// RecordSparkStageMemoryPeakDataPoint adds a data point to spark.stage.memory.peak metric.
func (mb *MetricsBuilder) RecordSparkStageMemoryPeakDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	mb.metricSparkStageMemoryPeak.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue)
}

// RecordSparkStageMemorySpilledDataPoint adds a data point to spark.stage.memory.spilled metric.
func (mb *MetricsBuilder) RecordSparkStageMemorySpilledDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	mb.metricSparkStageMemorySpilled.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue)
}

// RecordSparkStageShuffleBlocksFetchedDataPoint adds a data point to spark.stage.shuffle.blocks_fetched metric.
func (mb *MetricsBuilder) RecordSparkStageShuffleBlocksFetchedDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool, sourceAttributeValue AttributeSource) {
	mb.metricSparkStageShuffleBlocksFetched.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue, sourceAttributeValue.String())
}

// RecordSparkStageShuffleFetchWaitTimeDataPoint adds a data point to spark.stage.shuffle.fetch_wait_time metric.
func (mb *MetricsBuilder) RecordSparkStageShuffleFetchWaitTimeDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	mb.metricSparkStageShuffleFetchWaitTime.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue)
}

// RecordSparkStageShuffleIoDiskDataPoint adds a data point to spark.stage.shuffle.io.disk metric.
func (mb *MetricsBuilder) RecordSparkStageShuffleIoDiskDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	mb.metricSparkStageShuffleIoDisk.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue)
}

// RecordSparkStageShuffleIoRecordsDataPoint adds a data point to spark.stage.shuffle.io.records metric.
func (mb *MetricsBuilder) RecordSparkStageShuffleIoRecordsDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool, directionAttributeValue AttributeDirection) {
	mb.metricSparkStageShuffleIoRecords.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue, directionAttributeValue.String())
}

// RecordSparkStageShuffleIoSizeDataPoint adds a data point to spark.stage.shuffle.io.size metric.
func (mb *MetricsBuilder) RecordSparkStageShuffleIoSizeDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool, sourceAttributeValue AttributeSource, directionAttributeValue AttributeDirection) {
	mb.metricSparkStageShuffleIoSize.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue, sourceAttributeValue.String(), directionAttributeValue.String())
}

// RecordSparkStageShuffleWriteTimeDataPoint adds a data point to spark.stage.shuffle.write_time metric.
func (mb *MetricsBuilder) RecordSparkStageShuffleWriteTimeDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	mb.metricSparkStageShuffleWriteTime.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue)
}

// RecordSparkStageTaskActiveDataPoint adds a data point to spark.stage.task.active metric.
func (mb *MetricsBuilder) RecordSparkStageTaskActiveDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	mb.metricSparkStageTaskActive.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue)
}

// RecordSparkStageTaskResultSizeDataPoint adds a data point to spark.stage.task.result_size metric.
func (mb *MetricsBuilder) RecordSparkStageTaskResultSizeDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool) {
	mb.metricSparkStageTaskResultSize.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue)
}

// RecordSparkStageTaskResultsDataPoint adds a data point to spark.stage.task.results metric.
func (mb *MetricsBuilder) RecordSparkStageTaskResultsDataPoint(ts pcommon.Timestamp, val int64, attemptIDAttributeValue int64, stageActiveAttributeValue bool, stageCompleteAttributeValue bool, stagePendingAttributeValue bool, stageFailedAttributeValue bool, stageTaskResultAttributeValue AttributeStageTaskResult) {
	mb.metricSparkStageTaskResults.recordDataPoint(mb.startTime, ts, val, attemptIDAttributeValue, stageActiveAttributeValue, stageCompleteAttributeValue, stagePendingAttributeValue, stageFailedAttributeValue, stageTaskResultAttributeValue.String())
}

// Reset resets metrics builder to its initial state. It should be used when external metrics source is restarted,
// and metrics builder should update its startTime and reset it's internal state accordingly.
func (mb *MetricsBuilder) Reset(options ...metricBuilderOption) {
	mb.startTime = pcommon.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op(mb)
	}
}
