{
  "resourceMetrics": [
    {
      "resource": {
        "attributes": [
          {
            "key": "spark.application.id",
            "value": {
              "stringValue": "local-1684767537244"
            }
          },
          {
            "key": "spark.application.name",
            "value": {
              "stringValue": "streaming-example"
            }
          }
        ]
      },
      "scopeMetrics": [
        {
          "scope": {
            "name": "otelcol/apachesparkreceiver",
            "version": "latest"
          },
          "metrics": [
            {
              "name": "spark.driver.block_manager.disk.usage",
              "description": "Disk space used by the BlockManager.",
              "unit": "mb",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2
              }
            },
            {
              "name": "spark.driver.block_manager.memory.usage",
              "description": "Memory usage for the driver's BlockManager.",
              "unit": "mb",
              "sum": {
                "dataPoints": [
                  {
                    "attributes": [
                      {
                        "key": "location",
                        "value": {
                          "stringValue": "off_heap"
                        }
                      },
                      {
                        "key": "state",
                        "value": {
                          "stringValue": "used"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  },
                  {
                    "attributes": [
                      {
                        "key": "location",
                        "value": {
                          "stringValue": "on_heap"
                        }
                      },
                      {
                        "key": "state",
                        "value": {
                          "stringValue": "used"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  },
                  {
                    "attributes": [
                      {
                        "key": "location",
                        "value": {
                          "stringValue": "off_heap"
                        }
                      },
                      {
                        "key": "state",
                        "value": {
                          "stringValue": "free"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  },
                  {
                    "attributes": [
                      {
                        "key": "location",
                        "value": {
                          "stringValue": "on_heap"
                        }
                      },
                      {
                        "key": "state",
                        "value": {
                          "stringValue": "free"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "434"
                  }
                ],
                "aggregationTemporality": 2
              }
            },
            {
              "name": "spark.driver.code_generator.compilation.average_time",
              "description": "Average time spent during CodeGenerator source code compilation operations.",
              "unit": "ms",
              "gauge": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asDouble": 19.381877214793917
                  }
                ]
              }
            },
            {
              "name": "spark.driver.code_generator.compilation.count",
              "description": "Number of source code compilation operations performed by the CodeGenerator.",
              "unit": "{ compilation }",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "8"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.driver.code_generator.generated_class.average_size",
              "description": "Average class size of the classes generated by the CodeGenerator.",
              "unit": "bytes",
              "gauge": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asDouble": 2309.1202570773694
                  }
                ]
              }
            },
            {
              "name": "spark.driver.code_generator.generated_class.count",
              "description": "Number of classes generated by the CodeGenerator.",
              "unit": "{ class }",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "22"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.driver.code_generator.generated_method.average_size",
              "description": "Average method size of the classes generated by the CodeGenerator.",
              "unit": "bytes",
              "gauge": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asDouble": 61.51011122278099
                  }
                ]
              }
            },
            {
              "name": "spark.driver.code_generator.generated_method.count",
              "description": "Number of methods generated by the CodeGenerator.",
              "unit": "{ method }",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "81"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.driver.code_generator.source_code.average_size",
              "description": "Average size of the source code generated by a CodeGenerator code generation operation.",
              "unit": "bytes",
              "gauge": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asDouble": 5224.562450389398
                  }
                ]
              }
            },
            {
              "name": "spark.driver.code_generator.source_code.operations",
              "description": "Number of source code generation operations performed by the CodeGenerator.",
              "unit": "{ operation }",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "8"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.driver.dag_scheduler.job.active",
              "description": "Number of active jobs currently being processed by the DAGScheduler.",
              "unit": "{ job }",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2
              }
            },
            {
              "name": "spark.driver.dag_scheduler.job.count",
              "description": "Number of jobs that have been submitted to the DAGScheduler.",
              "unit": "{ job }",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "1"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.driver.dag_scheduler.stage.count",
              "description": "Number of stages the DAGScheduler is either running or needs to run.",
              "unit": "{ stage }",
              "sum": {
                "dataPoints": [
                  {
                    "attributes": [
                      {
                        "key": "waiting",
                        "value": {
                          "boolValue": false
                        }
                      },
                      {
                        "key": "running",
                        "value": {
                          "boolValue": true
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  },
                  {
                    "attributes": [
                      {
                        "key": "waiting",
                        "value": {
                          "boolValue": true
                        }
                      },
                      {
                        "key": "running",
                        "value": {
                          "boolValue": false
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2
              }
            },
            {
              "name": "spark.driver.dag_scheduler.stage.failed",
              "description": "Number of failed stages run by the DAGScheduler.",
              "unit": "{ stage }",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.driver.executor.gc.operations",
              "description": "Number of garbage collection operations performed by the driver.",
              "unit": "{ gc_operation }",
              "sum": {
                "dataPoints": [
                  {
                    "attributes": [
                      {
                        "key": "gc_type",
                        "value": {
                          "stringValue": "minor"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "106"
                  },
                  {
                    "attributes": [
                      {
                        "key": "gc_type",
                        "value": {
                          "stringValue": "major"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "3"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.driver.executor.gc.time",
              "description": "Total elapsed time during garbage collection operations performed by the driver.",
              "unit": "ms",
              "sum": {
                "dataPoints": [
                  {
                    "attributes": [
                      {
                        "key": "gc_type",
                        "value": {
                          "stringValue": "minor"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "832"
                  },
                  {
                    "attributes": [
                      {
                        "key": "gc_type",
                        "value": {
                          "stringValue": "major"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "236"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.driver.executor.memory.execution",
              "description": "Amount of execution memory currently used by the driver.",
              "unit": "bytes",
              "sum": {
                "dataPoints": [
                  {
                    "attributes": [
                      {
                        "key": "location",
                        "value": {
                          "stringValue": "off_heap"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  },
                  {
                    "attributes": [
                      {
                        "key": "location",
                        "value": {
                          "stringValue": "on_heap"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2
              }
            },
            {
              "name": "spark.driver.executor.memory.jvm",
              "description": "Amount of memory used by the driver's JVM.",
              "unit": "bytes",
              "sum": {
                "dataPoints": [
                  {
                    "attributes": [
                      {
                        "key": "location",
                        "value": {
                          "stringValue": "off_heap"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "195771776"
                  },
                  {
                    "attributes": [
                      {
                        "key": "location",
                        "value": {
                          "stringValue": "on_heap"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "145641752"
                  }
                ],
                "aggregationTemporality": 2
              }
            },
            {
              "name": "spark.driver.executor.memory.pool",
              "description": "Amount of pool memory currently used by the driver.",
              "unit": "bytes",
              "sum": {
                "dataPoints": [
                  {
                    "attributes": [
                      {
                        "key": "type",
                        "value": {
                          "stringValue": "direct"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "33953"
                  },
                  {
                    "attributes": [
                      {
                        "key": "type",
                        "value": {
                          "stringValue": "mapped"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2
              }
            },
            {
              "name": "spark.driver.executor.memory.storage",
              "description": "Amount of storage memory currently used by the driver.",
              "unit": "bytes",
              "sum": {
                "dataPoints": [
                  {
                    "attributes": [
                      {
                        "key": "location",
                        "value": {
                          "stringValue": "off_heap"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  },
                  {
                    "attributes": [
                      {
                        "key": "location",
                        "value": {
                          "stringValue": "on_heap"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2
              }
            },
            {
              "name": "spark.driver.hive_external_catalog.file_cache_hits",
              "description": "Number of file cache hits on the HiveExternalCatalog.",
              "unit": "{ hit }",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.driver.hive_external_catalog.files_discovered",
              "description": "Number of files discovered while listing the partitions of a table in the Hive metastore",
              "unit": "{ file }",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.driver.hive_external_catalog.hive_client_calls",
              "description": "Number of calls to the underlying Hive Metastore client made by the Spark application.",
              "unit": "{ call }",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.driver.hive_external_catalog.parallel_listing_jobs",
              "description": "Number of parallel listing jobs initiated by the HiveExternalCatalog when listing partitions of a table.",
              "unit": "{ listing_job }",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.driver.hive_external_catalog.partitions_fetched",
              "description": "Table partitions fetched by the HiveExternalCatalog.",
              "unit": "{ partition }",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.driver.jvm_cpu_time",
              "description": "Current CPU time taken by the Spark driver.",
              "unit": "ns",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "146722360000"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.driver.live_listener_bus.dropped",
              "description": "Number of events that have been dropped by the LiveListenerBus.",
              "unit": "{ event }",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.driver.live_listener_bus.posted",
              "description": "Number of events that have been posted on the LiveListenerBus.",
              "unit": "{ event }",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "2089"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.driver.live_listener_bus.processing_time.average",
              "description": "Average time taken for the LiveListenerBus to process an event posted to it.",
              "unit": "ms",
              "gauge": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asDouble": 0.08063793586302476
                  }
                ]
              }
            },
            {
              "name": "spark.driver.live_listener_bus.queue_size",
              "description": "Number of events currently waiting to be processed by the LiveListenerBus.",
              "unit": "{ event }",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2
              }
            }
          ]
        }
      ]
    },
    {
      "resource": {
        "attributes": [
          {
            "key": "spark.application.id",
            "value": {
              "stringValue": "local-1684767537244"
            }
          },
          {
            "key": "spark.application.name",
            "value": {
              "stringValue": "streaming-example"
            }
          },
          {
            "key": "spark.stage.id",
            "value": {
              "intValue": "1"
            }
          }
        ]
      },
      "scopeMetrics": [
        {
          "scope": {
            "name": "otelcol/apachesparkreceiver",
            "version": "latest"
          },
          "metrics": [
            {
              "name": "spark.stage.disk.spilled",
              "description": "The amount of disk space used for storing portions of overly large data chunks that couldn't fit in memory in this stage.",
              "unit": "bytes",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.executor.cpu_time",
              "description": "CPU time spent by the executor in this stage.",
              "unit": "ns",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "2563047000"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.executor.run_time",
              "description": "Amount of time spent by the executor in this stage.",
              "unit": "ms",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "17556"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.io.records",
              "description": "Number of records written and read in this stage.",
              "unit": "{ record }",
              "sum": {
                "dataPoints": [
                  {
                    "attributes": [
                      {
                        "key": "direction",
                        "value": {
                          "stringValue": "in"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  },
                  {
                    "attributes": [
                      {
                        "key": "direction",
                        "value": {
                          "stringValue": "out"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.io.size",
              "description": "Amount of data written and read at this stage.",
              "unit": "bytes",
              "sum": {
                "dataPoints": [
                  {
                    "attributes": [
                      {
                        "key": "direction",
                        "value": {
                          "stringValue": "in"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  },
                  {
                    "attributes": [
                      {
                        "key": "direction",
                        "value": {
                          "stringValue": "out"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.jvm_gc_time",
              "description": "The amount of time the JVM spent on garbage collection in this stage.",
              "unit": "ms",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "817"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.memory.peak",
              "description": "Peak memory used by internal data structures created during shuffles, aggregations and joins in this stage.",
              "unit": "bytes",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "157286400"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.memory.spilled",
              "description": "The amount of memory moved to disk due to size constraints (spilled) in this stage.",
              "unit": "bytes",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.shuffle.blocks_fetched",
              "description": "Number of blocks fetched in shuffle operations in this stage.",
              "unit": "{ block }",
              "sum": {
                "dataPoints": [
                  {
                    "attributes": [
                      {
                        "key": "source",
                        "value": {
                          "stringValue": "remote"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  },
                  {
                    "attributes": [
                      {
                        "key": "source",
                        "value": {
                          "stringValue": "local"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.shuffle.fetch_wait_time",
              "description": "Time spent in this stage waiting for remote shuffle blocks.",
              "unit": "ms",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.shuffle.io.disk",
              "description": "Amount of data read to disk in shuffle operations (sometimes required for large blocks, as opposed to the default behavior of reading into memory).",
              "unit": "bytes",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.shuffle.io.read.size",
              "description": "Amount of data read in shuffle operations in this stage.",
              "unit": "bytes",
              "sum": {
                "dataPoints": [
                  {
                    "attributes": [
                      {
                        "key": "source",
                        "value": {
                          "stringValue": "local"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  },
                  {
                    "attributes": [
                      {
                        "key": "source",
                        "value": {
                          "stringValue": "remote"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.shuffle.io.records",
              "description": "Number of records written or read in shuffle operations in this stage.",
              "unit": "{ record }",
              "sum": {
                "dataPoints": [
                  {
                    "attributes": [
                      {
                        "key": "direction",
                        "value": {
                          "stringValue": "in"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  },
                  {
                    "attributes": [
                      {
                        "key": "direction",
                        "value": {
                          "stringValue": "out"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.shuffle.io.write.size",
              "description": "Amount of data written in shuffle operations in this stage.",
              "unit": "bytes",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.shuffle.write_time",
              "description": "Time spent blocking on writes to disk or buffer cache in this stage.",
              "unit": "ns",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.status",
              "description": "A one-hot encoding representing the status of this stage.",
              "unit": "{ status }",
              "sum": {
                "dataPoints": [
                  {
                    "attributes": [
                      {
                        "key": "active",
                        "value": {
                          "boolValue": true
                        }
                      },
                      {
                        "key": "complete",
                        "value": {
                          "boolValue": false
                        }
                      },
                      {
                        "key": "pending",
                        "value": {
                          "boolValue": false
                        }
                      },
                      {
                        "key": "failed",
                        "value": {
                          "boolValue": false
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2
              }
            },
            {
              "name": "spark.stage.task.active",
              "description": "Number of active tasks in this stage.",
              "unit": "{ task }",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2
              }
            },
            {
              "name": "spark.stage.task.result",
              "description": "Number of tasks with a specific result in this stage.",
              "unit": "{ task }",
              "sum": {
                "dataPoints": [
                  {
                    "attributes": [
                      {
                        "key": "result",
                        "value": {
                          "stringValue": "completed"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "200"
                  },
                  {
                    "attributes": [
                      {
                        "key": "result",
                        "value": {
                          "stringValue": "failed"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  },
                  {
                    "attributes": [
                      {
                        "key": "result",
                        "value": {
                          "stringValue": "killed"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.task.result_size",
              "description": "The amount of data transmitted back to the driver by all the tasks in this stage.",
              "unit": "bytes",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "1170841"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            }
          ]
        }
      ]
    },
    {
      "resource": {
        "attributes": [
          {
            "key": "spark.application.id",
            "value": {
              "stringValue": "local-1684767537244"
            }
          },
          {
            "key": "spark.application.name",
            "value": {
              "stringValue": "streaming-example"
            }
          },
          {
            "key": "spark.stage.id",
            "value": {
              "intValue": "0"
            }
          }
        ]
      },
      "scopeMetrics": [
        {
          "scope": {
            "name": "otelcol/apachesparkreceiver",
            "version": "latest"
          },
          "metrics": [
            {
              "name": "spark.stage.disk.spilled",
              "description": "The amount of disk space used for storing portions of overly large data chunks that couldn't fit in memory in this stage.",
              "unit": "bytes",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.executor.cpu_time",
              "description": "CPU time spent by the executor in this stage.",
              "unit": "ns",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "608676000"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.executor.run_time",
              "description": "Amount of time spent by the executor in this stage.",
              "unit": "ms",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "1321"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.io.records",
              "description": "Number of records written and read in this stage.",
              "unit": "{ record }",
              "sum": {
                "dataPoints": [
                  {
                    "attributes": [
                      {
                        "key": "direction",
                        "value": {
                          "stringValue": "in"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  },
                  {
                    "attributes": [
                      {
                        "key": "direction",
                        "value": {
                          "stringValue": "out"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.io.size",
              "description": "Amount of data written and read at this stage.",
              "unit": "bytes",
              "sum": {
                "dataPoints": [
                  {
                    "attributes": [
                      {
                        "key": "direction",
                        "value": {
                          "stringValue": "in"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  },
                  {
                    "attributes": [
                      {
                        "key": "direction",
                        "value": {
                          "stringValue": "out"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.jvm_gc_time",
              "description": "The amount of time the JVM spent on garbage collection in this stage.",
              "unit": "ms",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "72"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.memory.peak",
              "description": "Peak memory used by internal data structures created during shuffles, aggregations and joins in this stage.",
              "unit": "bytes",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "3145728"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.memory.spilled",
              "description": "The amount of memory moved to disk due to size constraints (spilled) in this stage.",
              "unit": "bytes",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.shuffle.blocks_fetched",
              "description": "Number of blocks fetched in shuffle operations in this stage.",
              "unit": "{ block }",
              "sum": {
                "dataPoints": [
                  {
                    "attributes": [
                      {
                        "key": "source",
                        "value": {
                          "stringValue": "remote"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  },
                  {
                    "attributes": [
                      {
                        "key": "source",
                        "value": {
                          "stringValue": "local"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.shuffle.fetch_wait_time",
              "description": "Time spent in this stage waiting for remote shuffle blocks.",
              "unit": "ms",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.shuffle.io.disk",
              "description": "Amount of data read to disk in shuffle operations (sometimes required for large blocks, as opposed to the default behavior of reading into memory).",
              "unit": "bytes",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.shuffle.io.read.size",
              "description": "Amount of data read in shuffle operations in this stage.",
              "unit": "bytes",
              "sum": {
                "dataPoints": [
                  {
                    "attributes": [
                      {
                        "key": "source",
                        "value": {
                          "stringValue": "local"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  },
                  {
                    "attributes": [
                      {
                        "key": "source",
                        "value": {
                          "stringValue": "remote"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.shuffle.io.records",
              "description": "Number of records written or read in shuffle operations in this stage.",
              "unit": "{ record }",
              "sum": {
                "dataPoints": [
                  {
                    "attributes": [
                      {
                        "key": "direction",
                        "value": {
                          "stringValue": "in"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  },
                  {
                    "attributes": [
                      {
                        "key": "direction",
                        "value": {
                          "stringValue": "out"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.shuffle.io.write.size",
              "description": "Amount of data written in shuffle operations in this stage.",
              "unit": "bytes",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.shuffle.write_time",
              "description": "Time spent blocking on writes to disk or buffer cache in this stage.",
              "unit": "ns",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.status",
              "description": "A one-hot encoding representing the status of this stage.",
              "unit": "{ status }",
              "sum": {
                "dataPoints": [
                  {
                    "attributes": [
                      {
                        "key": "active",
                        "value": {
                          "boolValue": false
                        }
                      },
                      {
                        "key": "complete",
                        "value": {
                          "boolValue": true
                        }
                      },
                      {
                        "key": "pending",
                        "value": {
                          "boolValue": false
                        }
                      },
                      {
                        "key": "failed",
                        "value": {
                          "boolValue": false
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2
              }
            },
            {
              "name": "spark.stage.task.active",
              "description": "Number of active tasks in this stage.",
              "unit": "{ task }",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2
              }
            },
            {
              "name": "spark.stage.task.result",
              "description": "Number of tasks with a specific result in this stage.",
              "unit": "{ task }",
              "sum": {
                "dataPoints": [
                  {
                    "attributes": [
                      {
                        "key": "result",
                        "value": {
                          "stringValue": "completed"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "12"
                  },
                  {
                    "attributes": [
                      {
                        "key": "result",
                        "value": {
                          "stringValue": "failed"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  },
                  {
                    "attributes": [
                      {
                        "key": "result",
                        "value": {
                          "stringValue": "killed"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.stage.task.result_size",
              "description": "The amount of data transmitted back to the driver by all the tasks in this stage.",
              "unit": "bytes",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "29112"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            }
          ]
        }
      ]
    },
    {
      "resource": {
        "attributes": [
          {
            "key": "spark.application.id",
            "value": {
              "stringValue": "local-1684767537244"
            }
          },
          {
            "key": "spark.application.name",
            "value": {
              "stringValue": "streaming-example"
            }
          },
          {
            "key": "spark.executor.id",
            "value": {
              "stringValue": "driver"
            }
          }
        ]
      },
      "scopeMetrics": [
        {
          "scope": {
            "name": "otelcol/apachesparkreceiver",
            "version": "latest"
          },
          "metrics": [
            {
              "name": "spark.executor.disk.usage",
              "description": "Disk space used by this executor for RDD storage.",
              "unit": "bytes",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2
              }
            },
            {
              "name": "spark.executor.gc_time",
              "description": "Elapsed time the JVM spent in garbage collection in this executor.",
              "unit": "ms",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "1068"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.executor.input_size",
              "description": "Amount of data input for this executor.",
              "unit": "bytes",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.executor.memory.usage",
              "description": "Storage memory used by this executor.",
              "unit": "bytes",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2
              }
            },
            {
              "name": "spark.executor.shuffle.io.size",
              "description": "Amount of data written and read during shuffle operations for this executor.",
              "unit": "bytes",
              "sum": {
                "dataPoints": [
                  {
                    "attributes": [
                      {
                        "key": "direction",
                        "value": {
                          "stringValue": "in"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  },
                  {
                    "attributes": [
                      {
                        "key": "direction",
                        "value": {
                          "stringValue": "out"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.executor.storage_memory.usage",
              "description": "The executor's storage memory usage.",
              "unit": "bytes",
              "sum": {
                "dataPoints": [
                  {
                    "attributes": [
                      {
                        "key": "location",
                        "value": {
                          "stringValue": "on_heap"
                        }
                      },
                      {
                        "key": "state",
                        "value": {
                          "stringValue": "used"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  },
                  {
                    "attributes": [
                      {
                        "key": "location",
                        "value": {
                          "stringValue": "on_heap"
                        }
                      },
                      {
                        "key": "state",
                        "value": {
                          "stringValue": "free"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  },
                  {
                    "attributes": [
                      {
                        "key": "location",
                        "value": {
                          "stringValue": "off_heap"
                        }
                      },
                      {
                        "key": "state",
                        "value": {
                          "stringValue": "used"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  },
                  {
                    "attributes": [
                      {
                        "key": "location",
                        "value": {
                          "stringValue": "off_heap"
                        }
                      },
                      {
                        "key": "state",
                        "value": {
                          "stringValue": "free"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2
              }
            },
            {
              "name": "spark.executor.task.active",
              "description": "Number of tasks currently running in this executor.",
              "unit": "{ task }",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2
              }
            },
            {
              "name": "spark.executor.task.limit",
              "description": "Maximum number of tasks that can run concurrently in this executor.",
              "unit": "{ task }",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "12"
                  }
                ],
                "aggregationTemporality": 2
              }
            },
            {
              "name": "spark.executor.task.result",
              "description": "Number of tasks with a specific result in this executor.",
              "unit": "{ task }",
              "sum": {
                "dataPoints": [
                  {
                    "attributes": [
                      {
                        "key": "result",
                        "value": {
                          "stringValue": "failed"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  },
                  {
                    "attributes": [
                      {
                        "key": "result",
                        "value": {
                          "stringValue": "completed"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "212"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.executor.time",
              "description": "Elapsed time the JVM spent executing tasks in this executor.",
              "unit": "ms",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "9143289"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            }
          ]
        }
      ]
    },
    {
      "resource": {
        "attributes": [
          {
            "key": "spark.application.id",
            "value": {
              "stringValue": "local-1684767537244"
            }
          },
          {
            "key": "spark.application.name",
            "value": {
              "stringValue": "streaming-example"
            }
          },
          {
            "key": "spark.job.id",
            "value": {
              "intValue": "0"
            }
          }
        ]
      },
      "scopeMetrics": [
        {
          "scope": {
            "name": "otelcol/apachesparkreceiver",
            "version": "latest"
          },
          "metrics": [
            {
              "name": "spark.job.stage.active",
              "description": "Number of active stages in this job.",
              "unit": "{ task }",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2
              }
            },
            {
              "name": "spark.job.stage.result",
              "description": "Number of stages with a specific result in this job.",
              "unit": "{ task }",
              "sum": {
                "dataPoints": [
                  {
                    "attributes": [
                      {
                        "key": "result",
                        "value": {
                          "stringValue": "completed"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "2"
                  },
                  {
                    "attributes": [
                      {
                        "key": "result",
                        "value": {
                          "stringValue": "skipped"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  },
                  {
                    "attributes": [
                      {
                        "key": "result",
                        "value": {
                          "stringValue": "failed"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            },
            {
              "name": "spark.job.task.active",
              "description": "Number of active tasks in this job.",
              "unit": "{ task }",
              "sum": {
                "dataPoints": [
                  {
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2
              }
            },
            {
              "name": "spark.job.task.result",
              "description": "Number of tasks with a specific result in this job.",
              "unit": "{ task }",
              "sum": {
                "dataPoints": [
                  {
                    "attributes": [
                      {
                        "key": "result",
                        "value": {
                          "stringValue": "completed"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "212"
                  },
                  {
                    "attributes": [
                      {
                        "key": "result",
                        "value": {
                          "stringValue": "skipped"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  },
                  {
                    "attributes": [
                      {
                        "key": "result",
                        "value": {
                          "stringValue": "failed"
                        }
                      }
                    ],
                    "startTimeUnixNano": "1684776619974947000",
                    "timeUnixNano": "1684776679975411000",
                    "asInt": "0"
                  }
                ],
                "aggregationTemporality": 2,
                "isMonotonic": true
              }
            }
          ]
        }
      ]
    }
  ]
}