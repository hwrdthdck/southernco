resourceMetrics:
  - resource: {}
    scopeMetrics:
      - metrics:
          - description: Disk space used by the BlockManager.
            name: spark.driver.block_manager.disk.diskSpaceUsed
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
            unit: mb
          - description: Memory remaining for the BlockManager.
            name: spark.driver.block_manager.memory.remaining
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: location
                      value:
                        stringValue: off_heap
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "434"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: location
                      value:
                        stringValue: on_heap
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
            unit: mb
          - description: Memory used by the BlockManager.
            name: spark.driver.block_manager.memory.used
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: location
                      value:
                        stringValue: off_heap
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: location
                      value:
                        stringValue: on_heap
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
            unit: mb
          - description: Average time spent during CodeGenerator source code compilation operations.
            gauge:
              dataPoints:
                - asDouble: 102.34631777515023
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
            name: spark.driver.code_generator.compilation.average_time
            unit: bytes
          - description: Number of source code compilation operations performed by the CodeGenerator.
            name: spark.driver.code_generator.compilation.count
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "8"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ compilations }'
          - description: Average class size of the classes generated by the CodeGenerator.
            gauge:
              dataPoints:
                - asDouble: 2409.8125357816552
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
            name: spark.driver.code_generator.generated_class.average_size
            unit: bytes
          - description: Number of classes generated by the CodeGenerator.
            name: spark.driver.code_generator.generated_class.count
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "22"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ classes }'
          - description: Average method size of the classes generated by the CodeGenerator.
            gauge:
              dataPoints:
                - asDouble: 61.34019077461248
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
            name: spark.driver.code_generator.generated_method.average_size
            unit: bytes
          - description: Number of methods generated by the CodeGenerator.
            name: spark.driver.code_generator.generated_method.count
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "81"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ methods }'
          - description: Average size of the source code generated by a CodeGenerator code generation operation.
            gauge:
              dataPoints:
                - asDouble: 5193.878352804497
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
            name: spark.driver.code_generator.source_code.average_size
            unit: bytes
          - description: Number of source code generation operations performed by the CodeGenerator.
            name: spark.driver.code_generator.source_code.count
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "8"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ operations }'
          - description: Number of active jobs currently being processed by the DAGScheduler.
            name: spark.driver.dag_scheduler.job.active_jobs
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "1"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
            unit: '{ jobs }'
          - description: Number of jobs that have been submitted to the DAGScheduler.
            name: spark.driver.dag_scheduler.job.all_jobs
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "1"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ jobs }'
          - description: Number of failed stages run by the DAGScheduler.
            name: spark.driver.dag_scheduler.stage.failed_stages
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ stages }'
          - description: Number of stages the DAGScheduler is currently running.
            name: spark.driver.dag_scheduler.stage.running_stages
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "1"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
            unit: '{ stages }'
          - description: Number of stages waiting to be run by the DAGScheduler.
            name: spark.driver.dag_scheduler.stage.waiting_stages
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
            unit: '{ stages }'
          - description: Amount of execution memory currently used by the driver.
            name: spark.driver.executor_metrics.execution_memory
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: location
                      value:
                        stringValue: off_heap
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: location
                      value:
                        stringValue: on_heap
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
            unit: bytes
          - description: Number of garbage collection operations performed.
            name: spark.driver.executor_metrics.gc_count
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "33"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: gc_type
                      value:
                        stringValue: minor
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: gc_type
                      value:
                        stringValue: major
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ gc_operations }'
          - description: Total elapsed time during garbage collection operations.
            name: spark.driver.executor_metrics.gc_time
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "97"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: gc_type
                      value:
                        stringValue: minor
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: gc_type
                      value:
                        stringValue: major
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: ms
          - description: Amount of memory used by the driver JVM.
            name: spark.driver.executor_metrics.jvm_memory
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "158895192"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: location
                      value:
                        stringValue: off_heap
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "154858904"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: location
                      value:
                        stringValue: on_heap
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
            unit: bytes
          - description: Amount of pool memory currently used by the driver.
            name: spark.driver.executor_metrics.pool_memory
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "32769"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: pool_memory_type
                      value:
                        stringValue: direct
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: pool_memory_type
                      value:
                        stringValue: mapped
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
            unit: bytes
          - description: Amount of storage memory currently used by the driver.
            name: spark.driver.executor_metrics.storage_memory
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: location
                      value:
                        stringValue: off_heap
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "578796"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: location
                      value:
                        stringValue: on_heap
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
            unit: bytes
          - description: Number of file cache hits on the HiveExternalCatalog.
            name: spark.driver.hive_external_catalog.file_cache_hits
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ hits }'
          - description: Number of files discovered while listing the partitions of a table in the Hive metastore
            name: spark.driver.hive_external_catalog.files_discovered
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ files }'
          - description: Number of calls to the underlying Hive Metastore client made by the Spark application.
            name: spark.driver.hive_external_catalog.hive_client_calls
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ calls }'
          - description: Number of parallel listing jobs initiated by the HiveExternalCatalog when listing partitions of a table.
            name: spark.driver.hive_external_catalog.parallel_listing_jobs
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ listing_jobs }'
          - description: Table partitions fetched by the HiveExternalCatalog.
            name: spark.driver.hive_external_catalog.partitions_fetched
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ partitions }'
          - description: Current CPU time taken by the Spark driver.
            name: spark.driver.jvm_cpu_time
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "32742193000"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: ns
          - description: Number of events that have been dropped by the LiveListenerBus.
            name: spark.driver.live_listener_bus.events_dropped
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ events }'
          - description: Number of events that have been posted on the LiveListenerBus.
            name: spark.driver.live_listener_bus.events_posted
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "248"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ events }'
          - description: Average time taken for the LiveListenerBus to process an event posted to it.
            gauge:
              dataPoints:
                - asDouble: 2.570765936935471
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
            name: spark.driver.live_listener_bus.listener_processing_time.average
            unit: ms
          - description: Number of events currently waiting to be processed by the LiveListenerBus.
            name: spark.driver.live_listener_bus.queue_size
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
            unit: '{ events }'
          - description: Number of tasks currently running in this executor.
            name: spark.executor.active_tasks
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: executor_id
                      value:
                        stringValue: driver
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
            unit: '{ tasks }'
          - description: Number of tasks that have been completed by this executor.
            name: spark.executor.completed_tasks
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "212"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: executor_id
                      value:
                        stringValue: driver
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ tasks }'
          - description: Disk space used by this executor for RDD storage.
            name: spark.executor.disk_used
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: executor_id
                      value:
                        stringValue: driver
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
            unit: bytes
          - description: Elapsed time the JVM spent executing tasks in this executor.
            name: spark.executor.duration
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "149891"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: executor_id
                      value:
                        stringValue: driver
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: ms
          - description: Number of tasks that have failed in this executor.
            name: spark.executor.failed_tasks
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: executor_id
                      value:
                        stringValue: driver
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ tasks }'
          - description: Elapsed time the JVM spent in garbage collection in this executor.
            name: spark.executor.gc_time
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "221"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: executor_id
                      value:
                        stringValue: driver
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: ms
          - description: Input bytes for this executor.
            name: spark.executor.input_bytes
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: executor_id
                      value:
                        stringValue: driver
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: bytes
          - description: Maximum number of tasks that can run concurrently in this executor.
            name: spark.executor.max_tasks
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "12"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: executor_id
                      value:
                        stringValue: driver
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
            unit: '{ tasks }'
          - description: Storage memory used by this executor.
            name: spark.executor.memory_used
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "100596"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: executor_id
                      value:
                        stringValue: driver
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
            unit: bytes
          - description: Number of bytes read during shuffle operations for this executor.
            name: spark.executor.shuffle_read_bytes
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: executor_id
                      value:
                        stringValue: driver
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: bytes
          - description: Number of bytes written during shuffle operations for this executor.
            name: spark.executor.shuffle_write_bytes
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: executor_id
                      value:
                        stringValue: driver
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: bytes
          - description: Total memory that can be used for storage.
            name: spark.executor.total_storage_memory
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: executor_id
                      value:
                        stringValue: driver
                    - key: location
                      value:
                        stringValue: on_heap
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: executor_id
                      value:
                        stringValue: driver
                    - key: location
                      value:
                        stringValue: off_heap
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
            unit: bytes
          - description: Amount of memory currently used for storage.
            name: spark.executor.used_storage_memory
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: executor_id
                      value:
                        stringValue: driver
                    - key: location
                      value:
                        stringValue: on_heap
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: executor_id
                      value:
                        stringValue: driver
                    - key: location
                      value:
                        stringValue: off_heap
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
            unit: bytes
          - description: Number of active stages in this job.
            name: spark.job.active_stages
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: job_id
                      value:
                        intValue: "0"
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
            unit: '{ tasks }'
          - description: Number of active tasks in this job.
            name: spark.job.active_tasks
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: job_id
                      value:
                        intValue: "0"
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
            unit: '{ tasks }'
          - description: Number of completed stages in this job.
            name: spark.job.completed_stages
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "2"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: job_id
                      value:
                        intValue: "0"
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ tasks }'
          - description: Number of completed tasks in this job.
            name: spark.job.completed_tasks
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "212"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: job_id
                      value:
                        intValue: "0"
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ tasks }'
          - description: Number of failed stages in this job.
            name: spark.job.failed_stages
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: job_id
                      value:
                        intValue: "0"
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ tasks }'
          - description: Number of failed tasks in this job.
            name: spark.job.failed_tasks
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: job_id
                      value:
                        intValue: "0"
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ tasks }'
          - description: Number of skipped stages in this job.
            name: spark.job.skipped_stages
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: job_id
                      value:
                        intValue: "0"
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ tasks }'
          - description: Number of skipped tasks in this job.
            name: spark.job.skipped_tasks
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: job_id
                      value:
                        intValue: "0"
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ tasks }'
          - description: Number of active tasks in this stage.
            name: spark.stage.active_tasks
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "1"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "0"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
            unit: '{ tasks }'
          - description: Number of complete tasks in this stage.
            name: spark.stage.complete_tasks
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "200"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "1"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "12"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "0"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ tasks }'
          - description: The amount of disk space used for storing portions of overly large data chunks that couldn’t fit in memory in this stage.
            name: spark.stage.disk_space_spilled
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "1"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "0"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: bytes
          - description: CPU time spent by the executor in this stage.
            name: spark.stage.executor_cpu_time
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "8516746000"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "1"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "1505965000"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "0"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: ns
          - description: Amount of time spent by the executor in this stage.
            name: spark.stage.executor_run_time
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "96205"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "1"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "8927"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "0"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: ms
          - description: Number of failed tasks in this stage.
            name: spark.stage.failed_tasks
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "1"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "0"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ tasks }'
          - description: Number of bytes read in this stage.
            name: spark.stage.input_bytes
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "1"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "0"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: bytes
          - description: Number of records read in this stage.
            name: spark.stage.input_records
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "1"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "0"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ records }'
          - description: The amount of time the JVM spent on garbage collection in this stage.
            name: spark.stage.jvm_gc_time
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "1370"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "1"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "156"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "0"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: bytes
          - description: Number of killed tasks in this stage.
            name: spark.stage.killed_tasks
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "1"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "0"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ tasks }'
          - description: The amount of memory moved to disk due to size constraints (spilled) in this stage.
            name: spark.stage.memory_spilled
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "1"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "0"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: bytes
          - description: Number of bytes written in this stage.
            name: spark.stage.output_bytes
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "1"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "0"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: bytes
          - description: Number of records written in this stage.
            name: spark.stage.output_records
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "1"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "0"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ records }'
          - description: Peak memory used by internal data structures created during shuffles, aggregations and joins in this stage.
            name: spark.stage.peak_execution_memory
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "157286400"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "1"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "3145728"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "0"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: bytes
          - description: The sum of the bytes transmitted back to the driver by all the tasks in this stage.
            name: spark.stage.result_size
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "1478081"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "1"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "29568"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "0"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: bytes
          - description: Number of blocks fetched in shuffle operations in this stage.
            name: spark.stage.shuffle.blocks_fetched
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "1"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                    - key: source
                      value:
                        stringValue: remote
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "1"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                    - key: source
                      value:
                        stringValue: local
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "0"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                    - key: source
                      value:
                        stringValue: remote
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "0"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                    - key: source
                      value:
                        stringValue: local
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ blocks }'
          - description: Number of bytes read in shuffle operations in this stage.
            name: spark.stage.shuffle.bytes_read
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "1"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                    - key: source
                      value:
                        stringValue: remote
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "1"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                    - key: source
                      value:
                        stringValue: local
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "0"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                    - key: source
                      value:
                        stringValue: remote
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "0"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                    - key: source
                      value:
                        stringValue: local
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: bytes
          - description: Time spent in this stage waiting for remote shuffle blocks.
            name: spark.stage.shuffle.fetch_wait_time
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "1"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "0"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: ms
          - description: Number of bytes read in shuffle operations in this stage.
            name: spark.stage.shuffle.read_bytes
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "1"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "0"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: bytes
          - description: Number of records read in shuffle operations in this stage.
            name: spark.stage.shuffle.read_records
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "1"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "0"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ records }'
          - description: Number of remote bytes read to disk in shuffle operations (sometimes required for large blocks, as opposed to the default behavior of reading into memory).
            name: spark.stage.shuffle.remote_bytes_read_to_disk
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "1"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "0"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: bytes
          - description: Number of bytes written in shuffle operations in this stage.
            name: spark.stage.shuffle.write_bytes
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "1"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "0"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: bytes
          - description: Number of records written in shuffle operations in this stage.
            name: spark.stage.shuffle.write_records
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "1"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "0"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: '{ records }'
          - description: Time spent blocking on writes to disk or buffer cache in this stage.
            name: spark.stage.shuffle.write_time
            sum:
              aggregationTemporality: 2
              dataPoints:
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "1"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
                - asInt: "0"
                  attributes:
                    - key: application_id
                      value:
                        stringValue: local-1682603253681
                    - key: application_name
                      value:
                        stringValue: streaming-example
                    - key: stage_id
                      value:
                        intValue: "0"
                    - key: attempt_id
                      value:
                        intValue: "0"
                    - key: stage_status
                      value:
                        stringValue: COMPLETE
                  startTimeUnixNano: "1682622246645221000"
                  timeUnixNano: "1682622246647075000"
              isMonotonic: true
            unit: ns
        scope:
          name: otelcol/apachesparkreceiver
          version: latest
