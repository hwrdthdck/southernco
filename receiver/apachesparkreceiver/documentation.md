[comment]: <> (Code generated by mdatagen. DO NOT EDIT.)

# apachespark

## Default Metrics

The following metrics are emitted by default. Each of them can be disabled by applying the following configuration:

```yaml
metrics:
  <metric_name>:
    enabled: false
```

### spark.block_manager.disk.usage

Disk space used by the BlockManager.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| mb | Sum | Int | Cumulative | false |

### spark.block_manager.memory.remaining

Memory remaining for the BlockManager.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| mb | Sum | Int | Cumulative | false |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| location | The location of the memory which is quantified in the metric. | Str: ``on_heap``, ``off_heap`` |

### spark.block_manager.memory.used

Memory used by the BlockManager.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| mb | Sum | Int | Cumulative | false |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| location | The location of the memory which is quantified in the metric. | Str: ``on_heap``, ``off_heap`` |

### spark.code_generator.compilation.average_time

Average time spent during CodeGenerator source code compilation operations.

| Unit | Metric Type | Value Type |
| ---- | ----------- | ---------- |
| ms | Gauge | Double |

### spark.code_generator.compilation.count

Number of source code compilation operations performed by the CodeGenerator.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { compilations } | Sum | Int | Cumulative | true |

### spark.code_generator.generated_class.average_size

Average class size of the classes generated by the CodeGenerator.

| Unit | Metric Type | Value Type |
| ---- | ----------- | ---------- |
| bytes | Gauge | Double |

### spark.code_generator.generated_class.count

Number of classes generated by the CodeGenerator.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { classes } | Sum | Int | Cumulative | true |

### spark.code_generator.generated_method.average_size

Average method size of the classes generated by the CodeGenerator.

| Unit | Metric Type | Value Type |
| ---- | ----------- | ---------- |
| bytes | Gauge | Double |

### spark.code_generator.generated_method.count

Number of methods generated by the CodeGenerator.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { methods } | Sum | Int | Cumulative | true |

### spark.code_generator.source_code.average_size

Average size of the source code generated by a CodeGenerator code generation operation.

| Unit | Metric Type | Value Type |
| ---- | ----------- | ---------- |
| bytes | Gauge | Double |

### spark.code_generator.source_code.operations

Number of source code generation operations performed by the CodeGenerator.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { operations } | Sum | Int | Cumulative | true |

### spark.componennt.executor.memory.execution

Amount of execution memory currently used by the component.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| bytes | Sum | Int | Cumulative | false |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| location | The location of the memory which is quantified in the metric. | Str: ``on_heap``, ``off_heap`` |

### spark.component.executor.gc.operations

Number of garbage collection operations performed by the component.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { gc_operations } | Sum | Int | Cumulative | true |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| gc_type | The type of the garbage collection performed for the metric. | Str: ``major``, ``minor`` |

### spark.component.executor.gc.time

Total elapsed time during garbage collection operations performed by the component.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| ms | Sum | Int | Cumulative | true |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| gc_type | The type of the garbage collection performed for the metric. | Str: ``major``, ``minor`` |

### spark.component.executor.jvm_memory

Amount of memory used by the component's JVM.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| bytes | Sum | Int | Cumulative | false |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| location | The location of the memory which is quantified in the metric. | Str: ``on_heap``, ``off_heap`` |

### spark.component.executor.memory.pool

Amount of pool memory currently used by the component.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| bytes | Sum | Int | Cumulative | false |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| pool_memory_type | The type of pool memory for which the metric was recorded. | Str: ``direct``, ``mapped`` |

### spark.component.executor.memory.storage

Amount of storage memory currently used by the component.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| bytes | Sum | Int | Cumulative | false |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| location | The location of the memory which is quantified in the metric. | Str: ``on_heap``, ``off_heap`` |

### spark.component.jvm_cpu_time

Current CPU time taken by the Spark component.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| ns | Sum | Int | Cumulative | true |

### spark.dag_scheduler.jobs.active

Number of active jobs currently being processed by the DAGScheduler.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { jobs } | Sum | Int | Cumulative | false |

### spark.dag_scheduler.jobs.count

Number of jobs that have been submitted to the DAGScheduler.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { jobs } | Sum | Int | Cumulative | true |

### spark.dag_scheduler.stages

Number of stages the DAGScheduler is either running or needs to run.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { stages } | Sum | Int | Cumulative | false |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| scheduler_waiting | Whether the stages which the metric describes are waiting to be run by the DAGScheduler. | Any Bool |
| scheduler_running | Whether the stages which the metric describes are currently being run by the DAGScheduler. | Any Bool |

### spark.dag_scheduler.stages.failed

Number of failed stages run by the DAGScheduler.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { stages } | Sum | Int | Cumulative | true |

### spark.executor.disk.usage

Disk space used by this executor for RDD storage.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| bytes | Sum | Int | Cumulative | false |

### spark.executor.gc_time

Elapsed time the JVM spent in garbage collection in this executor.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| ms | Sum | Int | Cumulative | true |

### spark.executor.input_size

Amount of data input for this executor.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| bytes | Sum | Int | Cumulative | true |

### spark.executor.memory.usage

Storage memory used by this executor.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| bytes | Sum | Int | Cumulative | false |

### spark.executor.shuffle.io.size

Amount of data written and read during shuffle operations for this executor.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| bytes | Sum | Int | Cumulative | true |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| direction | Whether the metric is in regards to input or output operations. | Str: ``in``, ``out`` |

### spark.executor.storage_memory.total

Total memory that can be used for storage.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| bytes | Sum | Int | Cumulative | false |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| location | The location of the memory which is quantified in the metric. | Str: ``on_heap``, ``off_heap`` |

### spark.executor.storage_memory.used

Amount of memory currently used for storage.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| bytes | Sum | Int | Cumulative | false |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| location | The location of the memory which is quantified in the metric. | Str: ``on_heap``, ``off_heap`` |

### spark.executor.tasks.active

Number of tasks currently running in this executor.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { tasks } | Sum | Int | Cumulative | false |

### spark.executor.tasks.max

Maximum number of tasks that can run concurrently in this executor.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { tasks } | Sum | Int | Cumulative | false |

### spark.executor.tasks.results

Number of tasks with a specific result in this executor.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { tasks } | Sum | Int | Cumulative | true |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| executor_task_result | The result of the executor tasks for which the metric was recorded. | Str: ``completed``, ``failed`` |

### spark.executor.time

Elapsed time the JVM spent executing tasks in this executor.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| ms | Sum | Int | Cumulative | true |

### spark.hive_external_catalog.file_cache_hits

Number of file cache hits on the HiveExternalCatalog.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { hits } | Sum | Int | Cumulative | true |

### spark.hive_external_catalog.files_discovered

Number of files discovered while listing the partitions of a table in the Hive metastore

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { files } | Sum | Int | Cumulative | true |

### spark.hive_external_catalog.hive_client_calls

Number of calls to the underlying Hive Metastore client made by the Spark application.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { calls } | Sum | Int | Cumulative | true |

### spark.hive_external_catalog.parallel_listing_jobs

Number of parallel listing jobs initiated by the HiveExternalCatalog when listing partitions of a table.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { listing_jobs } | Sum | Int | Cumulative | true |

### spark.hive_external_catalog.partitions_fetched

Table partitions fetched by the HiveExternalCatalog.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { partitions } | Sum | Int | Cumulative | true |

### spark.job.stages.active

Number of active stages in this job.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { tasks } | Sum | Int | Cumulative | false |

### spark.job.stages.results

Number of stages with a specific result in this job.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { tasks } | Sum | Int | Cumulative | true |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| job_stage_result | The result of the job stages for which the metric was recorded. | Str: ``completed``, ``failed``, ``skipped`` |

### spark.job.tasks.active

Number of active tasks in this job.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { tasks } | Sum | Int | Cumulative | false |

### spark.job.tasks.results

Number of tasks with a specific result in this job.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { tasks } | Sum | Int | Cumulative | true |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| job_task_result | The result of the job tasks for which the metric was recorded. | Str: ``completed``, ``failed``, ``skipped`` |

### spark.live_listener_bus.events_dropped

Number of events that have been dropped by the LiveListenerBus.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { events } | Sum | Int | Cumulative | true |

### spark.live_listener_bus.events_posted

Number of events that have been posted on the LiveListenerBus.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { events } | Sum | Int | Cumulative | true |

### spark.live_listener_bus.processing_time.average

Average time taken for the LiveListenerBus to process an event posted to it.

| Unit | Metric Type | Value Type |
| ---- | ----------- | ---------- |
| ms | Gauge | Double |

### spark.live_listener_bus.queue_size

Number of events currently waiting to be processed by the LiveListenerBus.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { events } | Sum | Int | Cumulative | false |

### spark.stage.disk.spilled

The amount of disk space used for storing portions of overly large data chunks that couldn’t fit in memory in this stage.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| bytes | Sum | Int | Cumulative | true |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| attempt_id | The ID of the stage attempt for which the metric was recorded. | Any Int |
| stage_active | Whether the stage for which the metric was recorded is active. | Any Bool |
| stage_complete | Whether the stage for which the metric was recorded is complete. | Any Bool |
| stage_pending | Whether the stage for which the metric was recorded is pending. | Any Bool |
| stage_failed | Whether the stage for which the metric was recorded is failed. | Any Bool |

### spark.stage.executor.cpu_time

CPU time spent by the executor in this stage.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| ns | Sum | Int | Cumulative | true |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| attempt_id | The ID of the stage attempt for which the metric was recorded. | Any Int |
| stage_active | Whether the stage for which the metric was recorded is active. | Any Bool |
| stage_complete | Whether the stage for which the metric was recorded is complete. | Any Bool |
| stage_pending | Whether the stage for which the metric was recorded is pending. | Any Bool |
| stage_failed | Whether the stage for which the metric was recorded is failed. | Any Bool |

### spark.stage.executor.run_time

Amount of time spent by the executor in this stage.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| ms | Sum | Int | Cumulative | true |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| attempt_id | The ID of the stage attempt for which the metric was recorded. | Any Int |
| stage_active | Whether the stage for which the metric was recorded is active. | Any Bool |
| stage_complete | Whether the stage for which the metric was recorded is complete. | Any Bool |
| stage_pending | Whether the stage for which the metric was recorded is pending. | Any Bool |
| stage_failed | Whether the stage for which the metric was recorded is failed. | Any Bool |

### spark.stage.io.records

Number of records written and read in this stage.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { records } | Sum | Int | Cumulative | true |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| attempt_id | The ID of the stage attempt for which the metric was recorded. | Any Int |
| stage_active | Whether the stage for which the metric was recorded is active. | Any Bool |
| stage_complete | Whether the stage for which the metric was recorded is complete. | Any Bool |
| stage_pending | Whether the stage for which the metric was recorded is pending. | Any Bool |
| stage_failed | Whether the stage for which the metric was recorded is failed. | Any Bool |
| direction | Whether the metric is in regards to input or output operations. | Str: ``in``, ``out`` |

### spark.stage.io.size

Amount of data written and read at this stage.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| bytes | Sum | Int | Cumulative | true |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| attempt_id | The ID of the stage attempt for which the metric was recorded. | Any Int |
| stage_active | Whether the stage for which the metric was recorded is active. | Any Bool |
| stage_complete | Whether the stage for which the metric was recorded is complete. | Any Bool |
| stage_pending | Whether the stage for which the metric was recorded is pending. | Any Bool |
| stage_failed | Whether the stage for which the metric was recorded is failed. | Any Bool |
| direction | Whether the metric is in regards to input or output operations. | Str: ``in``, ``out`` |

### spark.stage.jvm_gc_time

The amount of time the JVM spent on garbage collection in this stage.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| ms | Sum | Int | Cumulative | true |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| attempt_id | The ID of the stage attempt for which the metric was recorded. | Any Int |
| stage_active | Whether the stage for which the metric was recorded is active. | Any Bool |
| stage_complete | Whether the stage for which the metric was recorded is complete. | Any Bool |
| stage_pending | Whether the stage for which the metric was recorded is pending. | Any Bool |
| stage_failed | Whether the stage for which the metric was recorded is failed. | Any Bool |

### spark.stage.memory.peak

Peak memory used by internal data structures created during shuffles, aggregations and joins in this stage.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| bytes | Sum | Int | Cumulative | true |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| attempt_id | The ID of the stage attempt for which the metric was recorded. | Any Int |
| stage_active | Whether the stage for which the metric was recorded is active. | Any Bool |
| stage_complete | Whether the stage for which the metric was recorded is complete. | Any Bool |
| stage_pending | Whether the stage for which the metric was recorded is pending. | Any Bool |
| stage_failed | Whether the stage for which the metric was recorded is failed. | Any Bool |

### spark.stage.memory.spilled

The amount of memory moved to disk due to size constraints (spilled) in this stage.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| bytes | Sum | Int | Cumulative | true |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| attempt_id | The ID of the stage attempt for which the metric was recorded. | Any Int |
| stage_active | Whether the stage for which the metric was recorded is active. | Any Bool |
| stage_complete | Whether the stage for which the metric was recorded is complete. | Any Bool |
| stage_pending | Whether the stage for which the metric was recorded is pending. | Any Bool |
| stage_failed | Whether the stage for which the metric was recorded is failed. | Any Bool |

### spark.stage.shuffle.blocks_fetched

Number of blocks fetched in shuffle operations in this stage.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { blocks } | Sum | Int | Cumulative | true |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| attempt_id | The ID of the stage attempt for which the metric was recorded. | Any Int |
| stage_active | Whether the stage for which the metric was recorded is active. | Any Bool |
| stage_complete | Whether the stage for which the metric was recorded is complete. | Any Bool |
| stage_pending | Whether the stage for which the metric was recorded is pending. | Any Bool |
| stage_failed | Whether the stage for which the metric was recorded is failed. | Any Bool |
| source | The source from which data was fetched for the metric. | Str: ``local``, ``remote`` |

### spark.stage.shuffle.fetch_wait_time

Time spent in this stage waiting for remote shuffle blocks.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| ms | Sum | Int | Cumulative | true |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| attempt_id | The ID of the stage attempt for which the metric was recorded. | Any Int |
| stage_active | Whether the stage for which the metric was recorded is active. | Any Bool |
| stage_complete | Whether the stage for which the metric was recorded is complete. | Any Bool |
| stage_pending | Whether the stage for which the metric was recorded is pending. | Any Bool |
| stage_failed | Whether the stage for which the metric was recorded is failed. | Any Bool |

### spark.stage.shuffle.io.disk

Amount of data read to disk in shuffle operations (sometimes required for large blocks, as opposed to the default behavior of reading into memory).

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| bytes | Sum | Int | Cumulative | true |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| attempt_id | The ID of the stage attempt for which the metric was recorded. | Any Int |
| stage_active | Whether the stage for which the metric was recorded is active. | Any Bool |
| stage_complete | Whether the stage for which the metric was recorded is complete. | Any Bool |
| stage_pending | Whether the stage for which the metric was recorded is pending. | Any Bool |
| stage_failed | Whether the stage for which the metric was recorded is failed. | Any Bool |

### spark.stage.shuffle.io.records

Number of records written or read in shuffle operations in this stage.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { records } | Sum | Int | Cumulative | true |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| attempt_id | The ID of the stage attempt for which the metric was recorded. | Any Int |
| stage_active | Whether the stage for which the metric was recorded is active. | Any Bool |
| stage_complete | Whether the stage for which the metric was recorded is complete. | Any Bool |
| stage_pending | Whether the stage for which the metric was recorded is pending. | Any Bool |
| stage_failed | Whether the stage for which the metric was recorded is failed. | Any Bool |
| direction | Whether the metric is in regards to input or output operations. | Str: ``in``, ``out`` |

### spark.stage.shuffle.io.size

Amount of data written or read in shuffle operations in this stage.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| bytes | Sum | Int | Cumulative | true |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| attempt_id | The ID of the stage attempt for which the metric was recorded. | Any Int |
| stage_active | Whether the stage for which the metric was recorded is active. | Any Bool |
| stage_complete | Whether the stage for which the metric was recorded is complete. | Any Bool |
| stage_pending | Whether the stage for which the metric was recorded is pending. | Any Bool |
| stage_failed | Whether the stage for which the metric was recorded is failed. | Any Bool |
| source | The source from which data was fetched for the metric. | Str: ``local``, ``remote`` |
| direction | Whether the metric is in regards to input or output operations. | Str: ``in``, ``out`` |

### spark.stage.shuffle.write_time

Time spent blocking on writes to disk or buffer cache in this stage.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| ns | Sum | Int | Cumulative | true |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| attempt_id | The ID of the stage attempt for which the metric was recorded. | Any Int |
| stage_active | Whether the stage for which the metric was recorded is active. | Any Bool |
| stage_complete | Whether the stage for which the metric was recorded is complete. | Any Bool |
| stage_pending | Whether the stage for which the metric was recorded is pending. | Any Bool |
| stage_failed | Whether the stage for which the metric was recorded is failed. | Any Bool |

### spark.stage.task.active

Number of active tasks in this stage.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { tasks } | Sum | Int | Cumulative | false |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| attempt_id | The ID of the stage attempt for which the metric was recorded. | Any Int |
| stage_active | Whether the stage for which the metric was recorded is active. | Any Bool |
| stage_complete | Whether the stage for which the metric was recorded is complete. | Any Bool |
| stage_pending | Whether the stage for which the metric was recorded is pending. | Any Bool |
| stage_failed | Whether the stage for which the metric was recorded is failed. | Any Bool |

### spark.stage.task.result_size

The amount of data transmitted back to the driver by all the tasks in this stage.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| bytes | Sum | Int | Cumulative | true |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| attempt_id | The ID of the stage attempt for which the metric was recorded. | Any Int |
| stage_active | Whether the stage for which the metric was recorded is active. | Any Bool |
| stage_complete | Whether the stage for which the metric was recorded is complete. | Any Bool |
| stage_pending | Whether the stage for which the metric was recorded is pending. | Any Bool |
| stage_failed | Whether the stage for which the metric was recorded is failed. | Any Bool |

### spark.stage.task.results

Number of tasks with a specific result in this stage.

| Unit | Metric Type | Value Type | Aggregation Temporality | Monotonic |
| ---- | ----------- | ---------- | ----------------------- | --------- |
| { tasks } | Sum | Int | Cumulative | true |

#### Attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| attempt_id | The ID of the stage attempt for which the metric was recorded. | Any Int |
| stage_active | Whether the stage for which the metric was recorded is active. | Any Bool |
| stage_complete | Whether the stage for which the metric was recorded is complete. | Any Bool |
| stage_pending | Whether the stage for which the metric was recorded is pending. | Any Bool |
| stage_failed | Whether the stage for which the metric was recorded is failed. | Any Bool |
| stage_task_result | The result of the stage tasks for which the metric was recorded. | Str: ``completed``, ``failed``, ``killed`` |

## Resource Attributes

| Name | Description | Values | Enabled |
| ---- | ----------- | ------ | ------- |
| spark.application.id | The ID of the application for which the metric was recorded. | Any Str | true |
| spark.application.name | The name of the application for which the metric was recorded. | Any Str | true |
| spark.component.type | The type of Spark component for which the metric was recorded. | Any Str | true |
| spark.executor.id | The ID of the executor for which the metric was recorded. | Any Str | true |
| spark.job.id | The ID of the job for which the metric was recorded. | Any Int | true |
| spark.stage.id | The ID of the application stage for which the metric was recorded. | Any Int | true |
