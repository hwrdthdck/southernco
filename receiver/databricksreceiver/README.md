# Databricks Receiver

<!-- status autogenerated section -->
| Status                   |           |
| ------------------------ |-----------|
| Stability                | [development]   |
| Supported pipeline types | metrics   |
| Distributions            | [contrib] |

[development]: https://github.com/open-telemetry/opentelemetry-collector#development
[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib
<!-- end autogenerated section -->

The Databricks Receiver generates metrics about the operation of a Databricks
instance by querying both the Databricks
[API](https://docs.databricks.com/dev-tools/api/latest/index.html)
and endpoints provided by the Spark subsystem operating within the Databricks 
instance.

## Configuration

The following fields are required:

- `instance_name`: A string representing the name of the instance. This value
  gets set as a `databricks.instance.name` resource attribute.
- `endpoint`: The URL containing a protocol (http or https), hostname, and (
  optional) port of the Databricks API, without a trailing slash.
- `token`:
  An [access token](https://docs.databricks.com/dev-tools/api/latest/authentication.html)
  to authenticate to the Databricks API.
- `spark_org_id`: The Spark Org ID. See the Spark Subsystem Configuration
  section below for how to get this value.
- `spark_endpoint`: The URL containing a protocol (http or https), hostname,
  and (optional) port of the Spark API. See the Spark Subsystem Configuration
  section below for how to get this value.
- `spark_ui_port`: A number representing the Spark UI Port (typically 40001).
  See the Spark Subsystem Configuration section below for how to get this value.

The following field is optional:

- `collection_interval`: How often this receiver fetches information from the
  Databricks API.
  Must be a string readable
  by [time.ParseDuration](https://pkg.go.dev/time#ParseDuration). Defaults to *
  *30s**.

### Example

```yaml
databricks:
  instance_name: my-instance
  endpoint: https://dbr.example.net
  token: abc123
  spark_org_id: 1234567890
  spark_endpoint: https://spark.example.net
  spark_ui_port: 40001
  collection_interval: 10s
```

### Spark Subsystem Configuration

To get the configuration parameters this receiver will need to get Spark
metrics, run the following Scala notebook and copy its output values into your
config:

```
%scala
val sparkOrgId = spark.conf.get("spark.databricks.clusterUsageTags.clusterOwnerOrgId")
val sparkEndpoint = dbutils.notebook.getContext.apiUrl.get
val sparkUiPort = spark.conf.get("spark.ui.port")
```
