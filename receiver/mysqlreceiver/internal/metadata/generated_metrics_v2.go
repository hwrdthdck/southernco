// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"time"

	"go.opentelemetry.io/collector/model/pdata"
	conventions "go.opentelemetry.io/collector/model/semconv/v1.6.1"
)

// MetricSettings provides common settings for a particular metric.
type MetricSettings struct {
	Enabled bool `mapstructure:"enabled"`
}

// MetricsSettings provides settings for mysqlreceiver metrics.
type MetricsSettings struct {
	MysqlBufferPoolDataPages   MetricSettings `mapstructure:"mysql.buffer_pool.data_pages"`
	MysqlBufferPoolLimit       MetricSettings `mapstructure:"mysql.buffer_pool.limit"`
	MysqlBufferPoolOperations  MetricSettings `mapstructure:"mysql.buffer_pool.operations"`
	MysqlBufferPoolPageFlushes MetricSettings `mapstructure:"mysql.buffer_pool.page_flushes"`
	MysqlBufferPoolPages       MetricSettings `mapstructure:"mysql.buffer_pool.pages"`
	MysqlBufferPoolUsage       MetricSettings `mapstructure:"mysql.buffer_pool.usage"`
	MysqlCommands              MetricSettings `mapstructure:"mysql.commands"`
	MysqlDoubleWrites          MetricSettings `mapstructure:"mysql.double_writes"`
	MysqlHandlers              MetricSettings `mapstructure:"mysql.handlers"`
	MysqlLocks                 MetricSettings `mapstructure:"mysql.locks"`
	MysqlLogOperations         MetricSettings `mapstructure:"mysql.log_operations"`
	MysqlOperations            MetricSettings `mapstructure:"mysql.operations"`
	MysqlPageOperations        MetricSettings `mapstructure:"mysql.page_operations"`
	MysqlRowLocks              MetricSettings `mapstructure:"mysql.row_locks"`
	MysqlRowOperations         MetricSettings `mapstructure:"mysql.row_operations"`
	MysqlSorts                 MetricSettings `mapstructure:"mysql.sorts"`
	MysqlThreads               MetricSettings `mapstructure:"mysql.threads"`
}

func DefaultMetricsSettings() MetricsSettings {
	return MetricsSettings{
		MysqlBufferPoolDataPages: MetricSettings{
			Enabled: true,
		},
		MysqlBufferPoolLimit: MetricSettings{
			Enabled: true,
		},
		MysqlBufferPoolOperations: MetricSettings{
			Enabled: true,
		},
		MysqlBufferPoolPageFlushes: MetricSettings{
			Enabled: true,
		},
		MysqlBufferPoolPages: MetricSettings{
			Enabled: true,
		},
		MysqlBufferPoolUsage: MetricSettings{
			Enabled: true,
		},
		MysqlCommands: MetricSettings{
			Enabled: true,
		},
		MysqlDoubleWrites: MetricSettings{
			Enabled: true,
		},
		MysqlHandlers: MetricSettings{
			Enabled: true,
		},
		MysqlLocks: MetricSettings{
			Enabled: true,
		},
		MysqlLogOperations: MetricSettings{
			Enabled: true,
		},
		MysqlOperations: MetricSettings{
			Enabled: true,
		},
		MysqlPageOperations: MetricSettings{
			Enabled: true,
		},
		MysqlRowLocks: MetricSettings{
			Enabled: true,
		},
		MysqlRowOperations: MetricSettings{
			Enabled: true,
		},
		MysqlSorts: MetricSettings{
			Enabled: true,
		},
		MysqlThreads: MetricSettings{
			Enabled: true,
		},
	}
}

type metricMysqlBufferPoolDataPages struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.buffer_pool.data_pages metric with initial data.
func (m *metricMysqlBufferPoolDataPages) init() {
	m.data.SetName("mysql.buffer_pool.data_pages")
	m.data.SetDescription("The number of data pages in the InnoDB buffer pool.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlBufferPoolDataPages) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, bufferPoolDataAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.BufferPoolData, pdata.NewAttributeValueString(bufferPoolDataAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlBufferPoolDataPages) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlBufferPoolDataPages) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlBufferPoolDataPages(settings MetricSettings) metricMysqlBufferPoolDataPages {
	m := metricMysqlBufferPoolDataPages{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlBufferPoolLimit struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.buffer_pool.limit metric with initial data.
func (m *metricMysqlBufferPoolLimit) init() {
	m.data.SetName("mysql.buffer_pool.limit")
	m.data.SetDescription("The configured size of the InnoDB buffer pool.")
	m.data.SetUnit("By")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

func (m *metricMysqlBufferPoolLimit) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlBufferPoolLimit) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlBufferPoolLimit) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlBufferPoolLimit(settings MetricSettings) metricMysqlBufferPoolLimit {
	m := metricMysqlBufferPoolLimit{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlBufferPoolOperations struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.buffer_pool.operations metric with initial data.
func (m *metricMysqlBufferPoolOperations) init() {
	m.data.SetName("mysql.buffer_pool.operations")
	m.data.SetDescription("The number of operations on the InnoDB buffer pool.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlBufferPoolOperations) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, bufferPoolOperationsAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.BufferPoolOperations, pdata.NewAttributeValueString(bufferPoolOperationsAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlBufferPoolOperations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlBufferPoolOperations) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlBufferPoolOperations(settings MetricSettings) metricMysqlBufferPoolOperations {
	m := metricMysqlBufferPoolOperations{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlBufferPoolPageFlushes struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.buffer_pool.page_flushes metric with initial data.
func (m *metricMysqlBufferPoolPageFlushes) init() {
	m.data.SetName("mysql.buffer_pool.page_flushes")
	m.data.SetDescription("The number of requests to flush pages from the InnoDB buffer pool.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
}

func (m *metricMysqlBufferPoolPageFlushes) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlBufferPoolPageFlushes) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlBufferPoolPageFlushes) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlBufferPoolPageFlushes(settings MetricSettings) metricMysqlBufferPoolPageFlushes {
	m := metricMysqlBufferPoolPageFlushes{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlBufferPoolPages struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.buffer_pool.pages metric with initial data.
func (m *metricMysqlBufferPoolPages) init() {
	m.data.SetName("mysql.buffer_pool.pages")
	m.data.SetDescription("The number of pages in the InnoDB buffer pool.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlBufferPoolPages) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, bufferPoolPagesAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.BufferPoolPages, pdata.NewAttributeValueString(bufferPoolPagesAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlBufferPoolPages) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlBufferPoolPages) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlBufferPoolPages(settings MetricSettings) metricMysqlBufferPoolPages {
	m := metricMysqlBufferPoolPages{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlBufferPoolUsage struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.buffer_pool.usage metric with initial data.
func (m *metricMysqlBufferPoolUsage) init() {
	m.data.SetName("mysql.buffer_pool.usage")
	m.data.SetDescription("The number of bytes in the InnoDB buffer pool.")
	m.data.SetUnit("By")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlBufferPoolUsage) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, bufferPoolDataAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.BufferPoolData, pdata.NewAttributeValueString(bufferPoolDataAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlBufferPoolUsage) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlBufferPoolUsage) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlBufferPoolUsage(settings MetricSettings) metricMysqlBufferPoolUsage {
	m := metricMysqlBufferPoolUsage{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlCommands struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.commands metric with initial data.
func (m *metricMysqlCommands) init() {
	m.data.SetName("mysql.commands")
	m.data.SetDescription("The number of times each type of command has been executed.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlCommands) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, commandAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.Command, pdata.NewAttributeValueString(commandAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlCommands) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlCommands) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlCommands(settings MetricSettings) metricMysqlCommands {
	m := metricMysqlCommands{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlDoubleWrites struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.double_writes metric with initial data.
func (m *metricMysqlDoubleWrites) init() {
	m.data.SetName("mysql.double_writes")
	m.data.SetDescription("The number of writes to the InnoDB doublewrite buffer.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlDoubleWrites) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, doubleWritesAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.DoubleWrites, pdata.NewAttributeValueString(doubleWritesAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlDoubleWrites) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlDoubleWrites) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlDoubleWrites(settings MetricSettings) metricMysqlDoubleWrites {
	m := metricMysqlDoubleWrites{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlHandlers struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.handlers metric with initial data.
func (m *metricMysqlHandlers) init() {
	m.data.SetName("mysql.handlers")
	m.data.SetDescription("The number of requests to various MySQL handlers.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlHandlers) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, handlerAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.Handler, pdata.NewAttributeValueString(handlerAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlHandlers) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlHandlers) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlHandlers(settings MetricSettings) metricMysqlHandlers {
	m := metricMysqlHandlers{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlLocks struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.locks metric with initial data.
func (m *metricMysqlLocks) init() {
	m.data.SetName("mysql.locks")
	m.data.SetDescription("The number of MySQL locks.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlLocks) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, locksAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.Locks, pdata.NewAttributeValueString(locksAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlLocks) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlLocks) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlLocks(settings MetricSettings) metricMysqlLocks {
	m := metricMysqlLocks{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlLogOperations struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.log_operations metric with initial data.
func (m *metricMysqlLogOperations) init() {
	m.data.SetName("mysql.log_operations")
	m.data.SetDescription("The number of InndoDB log operations.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlLogOperations) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, logOperationsAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.LogOperations, pdata.NewAttributeValueString(logOperationsAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlLogOperations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlLogOperations) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlLogOperations(settings MetricSettings) metricMysqlLogOperations {
	m := metricMysqlLogOperations{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlOperations struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.operations metric with initial data.
func (m *metricMysqlOperations) init() {
	m.data.SetName("mysql.operations")
	m.data.SetDescription("The number of InndoDB operations.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlOperations) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, operationsAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.Operations, pdata.NewAttributeValueString(operationsAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlOperations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlOperations) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlOperations(settings MetricSettings) metricMysqlOperations {
	m := metricMysqlOperations{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlPageOperations struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.page_operations metric with initial data.
func (m *metricMysqlPageOperations) init() {
	m.data.SetName("mysql.page_operations")
	m.data.SetDescription("The number of InndoDB page operations.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlPageOperations) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, pageOperationsAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.PageOperations, pdata.NewAttributeValueString(pageOperationsAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlPageOperations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlPageOperations) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlPageOperations(settings MetricSettings) metricMysqlPageOperations {
	m := metricMysqlPageOperations{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlRowLocks struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.row_locks metric with initial data.
func (m *metricMysqlRowLocks) init() {
	m.data.SetName("mysql.row_locks")
	m.data.SetDescription("The number of InndoDB row locks.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlRowLocks) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, rowLocksAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.RowLocks, pdata.NewAttributeValueString(rowLocksAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlRowLocks) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlRowLocks) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlRowLocks(settings MetricSettings) metricMysqlRowLocks {
	m := metricMysqlRowLocks{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlRowOperations struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.row_operations metric with initial data.
func (m *metricMysqlRowOperations) init() {
	m.data.SetName("mysql.row_operations")
	m.data.SetDescription("The number of InndoDB row operations.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlRowOperations) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, rowOperationsAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.RowOperations, pdata.NewAttributeValueString(rowOperationsAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlRowOperations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlRowOperations) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlRowOperations(settings MetricSettings) metricMysqlRowOperations {
	m := metricMysqlRowOperations{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlSorts struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.sorts metric with initial data.
func (m *metricMysqlSorts) init() {
	m.data.SetName("mysql.sorts")
	m.data.SetDescription("The number of MySQL sorts.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlSorts) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, sortsAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.Sorts, pdata.NewAttributeValueString(sortsAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlSorts) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlSorts) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlSorts(settings MetricSettings) metricMysqlSorts {
	m := metricMysqlSorts{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlThreads struct {
	data     pdata.Metric   // data buffer for generated metric.
	settings MetricSettings // metric settings provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.threads metric with initial data.
func (m *metricMysqlThreads) init() {
	m.data.SetName("mysql.threads")
	m.data.SetDescription("The state of MySQL threads.")
	m.data.SetUnit("1")
	m.data.SetDataType(pdata.MetricDataTypeSum)
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pdata.MetricAggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlThreads) recordDataPoint(start pdata.Timestamp, ts pdata.Timestamp, val int64, threadsAttributeValue string) {
	if !m.settings.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntVal(val)
	dp.Attributes().Insert(A.Threads, pdata.NewAttributeValueString(threadsAttributeValue))
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlThreads) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlThreads) emit(metrics pdata.MetricSlice) {
	if m.settings.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlThreads(settings MetricSettings) metricMysqlThreads {
	m := metricMysqlThreads{settings: settings}
	if settings.Enabled {
		m.data = pdata.NewMetric()
		m.init()
	}
	return m
}

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user settings.
type MetricsBuilder struct {
	startTime        pdata.Timestamp
	settings         MetricsSettings
	resourceBuilders []*ResourceBuilder
}

// metricBuilderOption applies changes to default metrics builder.
type metricBuilderOption func(*MetricsBuilder)

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pdata.Timestamp) metricBuilderOption {
	return func(mb *MetricsBuilder) {
		mb.startTime = startTime
	}
}

func NewMetricsBuilder(settings MetricsSettings, options ...metricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		startTime: pdata.NewTimestampFromTime(time.Now()),
		settings:  settings,
	}
	for _, op := range options {
		op(mb)
	}
	return mb
}

// emitOption applies changes to pdata.Metrics emitted.
type emitOption func(*pdata.Metrics)

// WithResource copies the pdata.Resource into the emitted pdata.Metrics.
func WithResource(resource pdata.Resource) emitOption {
	return func(md *pdata.Metrics) {
		resource.CopyTo(md.ResourceMetrics().At(0).Resource())
	}
}

// WithCapacity calls EnsureCapacity on the pdata.Metrics.
func WithCapacity(capacity int) emitOption {
	return func(md *pdata.Metrics) {
		if capacity > 0 {
			md.ResourceMetrics().At(0).InstrumentationLibraryMetrics().At(0).Metrics().EnsureCapacity(capacity)
		}
	}
}

// Emit appends generated metrics to a pdata.MetricsSlice and updates the internal state to be ready for recording
// another set of data points. This function will be doing all transformations required to produce metric representation
// defined in metadata and user settings, e.g. delta/cumulative translation.
func (mb *MetricsBuilder) Emit(options ...emitOption) pdata.Metrics {
	md := mb.newMetricData()

	for _, op := range options {
		op(&md)
	}

	for _, rb := range mb.resourceBuilders {
		rm := md.ResourceMetrics().AppendEmpty()
		ilm := rm.InstrumentationLibraryMetrics().AppendEmpty()
		ilm.InstrumentationLibrary().SetName("otelcol/mysqlreceiver")
		rm.SetSchemaUrl(conventions.SchemaURL)
		rb.emit(rm)
	}
	return md
}

type ResourceBuilder struct {
	resource                         pdata.Resource
	startTime                        pdata.Timestamp
	metricMysqlBufferPoolDataPages   metricMysqlBufferPoolDataPages
	metricMysqlBufferPoolLimit       metricMysqlBufferPoolLimit
	metricMysqlBufferPoolOperations  metricMysqlBufferPoolOperations
	metricMysqlBufferPoolPageFlushes metricMysqlBufferPoolPageFlushes
	metricMysqlBufferPoolPages       metricMysqlBufferPoolPages
	metricMysqlBufferPoolUsage       metricMysqlBufferPoolUsage
	metricMysqlCommands              metricMysqlCommands
	metricMysqlDoubleWrites          metricMysqlDoubleWrites
	metricMysqlHandlers              metricMysqlHandlers
	metricMysqlLocks                 metricMysqlLocks
	metricMysqlLogOperations         metricMysqlLogOperations
	metricMysqlOperations            metricMysqlOperations
	metricMysqlPageOperations        metricMysqlPageOperations
	metricMysqlRowLocks              metricMysqlRowLocks
	metricMysqlRowOperations         metricMysqlRowOperations
	metricMysqlSorts                 metricMysqlSorts
	metricMysqlThreads               metricMysqlThreads
}

func (rb *ResourceBuilder) Attributes() pdata.AttributeMap {
	return rb.resource.Attributes()
}

func (rb *ResourceBuilder) emit(rm pdata.ResourceMetrics) {
	rb.resource.CopyTo(rm.Resource())

	metrics := rm.InstrumentationLibraryMetrics().At(0).Metrics()

	rb.metricMysqlBufferPoolDataPages.emit(metrics)
	rb.metricMysqlBufferPoolLimit.emit(metrics)
	rb.metricMysqlBufferPoolOperations.emit(metrics)
	rb.metricMysqlBufferPoolPageFlushes.emit(metrics)
	rb.metricMysqlBufferPoolPages.emit(metrics)
	rb.metricMysqlBufferPoolUsage.emit(metrics)
	rb.metricMysqlCommands.emit(metrics)
	rb.metricMysqlDoubleWrites.emit(metrics)
	rb.metricMysqlHandlers.emit(metrics)
	rb.metricMysqlLocks.emit(metrics)
	rb.metricMysqlLogOperations.emit(metrics)
	rb.metricMysqlOperations.emit(metrics)
	rb.metricMysqlPageOperations.emit(metrics)
	rb.metricMysqlRowLocks.emit(metrics)
	rb.metricMysqlRowOperations.emit(metrics)
	rb.metricMysqlSorts.emit(metrics)
	rb.metricMysqlThreads.emit(metrics)
}

func (mb *MetricsBuilder) NewResourceBuilder() *ResourceBuilder {
	rb := ResourceBuilder{
		metricMysqlBufferPoolDataPages:   newMetricMysqlBufferPoolDataPages(mb.settings.MysqlBufferPoolDataPages),
		metricMysqlBufferPoolLimit:       newMetricMysqlBufferPoolLimit(mb.settings.MysqlBufferPoolLimit),
		metricMysqlBufferPoolOperations:  newMetricMysqlBufferPoolOperations(mb.settings.MysqlBufferPoolOperations),
		metricMysqlBufferPoolPageFlushes: newMetricMysqlBufferPoolPageFlushes(mb.settings.MysqlBufferPoolPageFlushes),
		metricMysqlBufferPoolPages:       newMetricMysqlBufferPoolPages(mb.settings.MysqlBufferPoolPages),
		metricMysqlBufferPoolUsage:       newMetricMysqlBufferPoolUsage(mb.settings.MysqlBufferPoolUsage),
		metricMysqlCommands:              newMetricMysqlCommands(mb.settings.MysqlCommands),
		metricMysqlDoubleWrites:          newMetricMysqlDoubleWrites(mb.settings.MysqlDoubleWrites),
		metricMysqlHandlers:              newMetricMysqlHandlers(mb.settings.MysqlHandlers),
		metricMysqlLocks:                 newMetricMysqlLocks(mb.settings.MysqlLocks),
		metricMysqlLogOperations:         newMetricMysqlLogOperations(mb.settings.MysqlLogOperations),
		metricMysqlOperations:            newMetricMysqlOperations(mb.settings.MysqlOperations),
		metricMysqlPageOperations:        newMetricMysqlPageOperations(mb.settings.MysqlPageOperations),
		metricMysqlRowLocks:              newMetricMysqlRowLocks(mb.settings.MysqlRowLocks),
		metricMysqlRowOperations:         newMetricMysqlRowOperations(mb.settings.MysqlRowOperations),
		metricMysqlSorts:                 newMetricMysqlSorts(mb.settings.MysqlSorts),
		metricMysqlThreads:               newMetricMysqlThreads(mb.settings.MysqlThreads),
		resource:                         pdata.NewResource(),
	}
	mb.resourceBuilders = append(mb.resourceBuilders, &rb)
	return &rb
}

// RecordMysqlBufferPoolDataPagesDataPoint adds a data point to mysql.buffer_pool.data_pages metric.
func (rb *ResourceBuilder) RecordMysqlBufferPoolDataPagesDataPoint(ts pdata.Timestamp, val int64, bufferPoolDataAttributeValue string) {
	rb.metricMysqlBufferPoolDataPages.recordDataPoint(rb.startTime, ts, val, bufferPoolDataAttributeValue)
}

// RecordMysqlBufferPoolLimitDataPoint adds a data point to mysql.buffer_pool.limit metric.
func (rb *ResourceBuilder) RecordMysqlBufferPoolLimitDataPoint(ts pdata.Timestamp, val int64) {
	rb.metricMysqlBufferPoolLimit.recordDataPoint(rb.startTime, ts, val)
}

// RecordMysqlBufferPoolOperationsDataPoint adds a data point to mysql.buffer_pool.operations metric.
func (rb *ResourceBuilder) RecordMysqlBufferPoolOperationsDataPoint(ts pdata.Timestamp, val int64, bufferPoolOperationsAttributeValue string) {
	rb.metricMysqlBufferPoolOperations.recordDataPoint(rb.startTime, ts, val, bufferPoolOperationsAttributeValue)
}

// RecordMysqlBufferPoolPageFlushesDataPoint adds a data point to mysql.buffer_pool.page_flushes metric.
func (rb *ResourceBuilder) RecordMysqlBufferPoolPageFlushesDataPoint(ts pdata.Timestamp, val int64) {
	rb.metricMysqlBufferPoolPageFlushes.recordDataPoint(rb.startTime, ts, val)
}

// RecordMysqlBufferPoolPagesDataPoint adds a data point to mysql.buffer_pool.pages metric.
func (rb *ResourceBuilder) RecordMysqlBufferPoolPagesDataPoint(ts pdata.Timestamp, val int64, bufferPoolPagesAttributeValue string) {
	rb.metricMysqlBufferPoolPages.recordDataPoint(rb.startTime, ts, val, bufferPoolPagesAttributeValue)
}

// RecordMysqlBufferPoolUsageDataPoint adds a data point to mysql.buffer_pool.usage metric.
func (rb *ResourceBuilder) RecordMysqlBufferPoolUsageDataPoint(ts pdata.Timestamp, val int64, bufferPoolDataAttributeValue string) {
	rb.metricMysqlBufferPoolUsage.recordDataPoint(rb.startTime, ts, val, bufferPoolDataAttributeValue)
}

// RecordMysqlCommandsDataPoint adds a data point to mysql.commands metric.
func (rb *ResourceBuilder) RecordMysqlCommandsDataPoint(ts pdata.Timestamp, val int64, commandAttributeValue string) {
	rb.metricMysqlCommands.recordDataPoint(rb.startTime, ts, val, commandAttributeValue)
}

// RecordMysqlDoubleWritesDataPoint adds a data point to mysql.double_writes metric.
func (rb *ResourceBuilder) RecordMysqlDoubleWritesDataPoint(ts pdata.Timestamp, val int64, doubleWritesAttributeValue string) {
	rb.metricMysqlDoubleWrites.recordDataPoint(rb.startTime, ts, val, doubleWritesAttributeValue)
}

// RecordMysqlHandlersDataPoint adds a data point to mysql.handlers metric.
func (rb *ResourceBuilder) RecordMysqlHandlersDataPoint(ts pdata.Timestamp, val int64, handlerAttributeValue string) {
	rb.metricMysqlHandlers.recordDataPoint(rb.startTime, ts, val, handlerAttributeValue)
}

// RecordMysqlLocksDataPoint adds a data point to mysql.locks metric.
func (rb *ResourceBuilder) RecordMysqlLocksDataPoint(ts pdata.Timestamp, val int64, locksAttributeValue string) {
	rb.metricMysqlLocks.recordDataPoint(rb.startTime, ts, val, locksAttributeValue)
}

// RecordMysqlLogOperationsDataPoint adds a data point to mysql.log_operations metric.
func (rb *ResourceBuilder) RecordMysqlLogOperationsDataPoint(ts pdata.Timestamp, val int64, logOperationsAttributeValue string) {
	rb.metricMysqlLogOperations.recordDataPoint(rb.startTime, ts, val, logOperationsAttributeValue)
}

// RecordMysqlOperationsDataPoint adds a data point to mysql.operations metric.
func (rb *ResourceBuilder) RecordMysqlOperationsDataPoint(ts pdata.Timestamp, val int64, operationsAttributeValue string) {
	rb.metricMysqlOperations.recordDataPoint(rb.startTime, ts, val, operationsAttributeValue)
}

// RecordMysqlPageOperationsDataPoint adds a data point to mysql.page_operations metric.
func (rb *ResourceBuilder) RecordMysqlPageOperationsDataPoint(ts pdata.Timestamp, val int64, pageOperationsAttributeValue string) {
	rb.metricMysqlPageOperations.recordDataPoint(rb.startTime, ts, val, pageOperationsAttributeValue)
}

// RecordMysqlRowLocksDataPoint adds a data point to mysql.row_locks metric.
func (rb *ResourceBuilder) RecordMysqlRowLocksDataPoint(ts pdata.Timestamp, val int64, rowLocksAttributeValue string) {
	rb.metricMysqlRowLocks.recordDataPoint(rb.startTime, ts, val, rowLocksAttributeValue)
}

// RecordMysqlRowOperationsDataPoint adds a data point to mysql.row_operations metric.
func (rb *ResourceBuilder) RecordMysqlRowOperationsDataPoint(ts pdata.Timestamp, val int64, rowOperationsAttributeValue string) {
	rb.metricMysqlRowOperations.recordDataPoint(rb.startTime, ts, val, rowOperationsAttributeValue)
}

// RecordMysqlSortsDataPoint adds a data point to mysql.sorts metric.
func (rb *ResourceBuilder) RecordMysqlSortsDataPoint(ts pdata.Timestamp, val int64, sortsAttributeValue string) {
	rb.metricMysqlSorts.recordDataPoint(rb.startTime, ts, val, sortsAttributeValue)
}

// RecordMysqlThreadsDataPoint adds a data point to mysql.threads metric.
func (rb *ResourceBuilder) RecordMysqlThreadsDataPoint(ts pdata.Timestamp, val int64, threadsAttributeValue string) {
	rb.metricMysqlThreads.recordDataPoint(rb.startTime, ts, val, threadsAttributeValue)
}

// Reset resets metrics builder to its initial state. It should be used when external metrics source is restarted,
// and metrics builder should update its startTime and reset it's internal state accordingly.
func (mb *MetricsBuilder) Reset(options ...metricBuilderOption) {
	mb.startTime = pdata.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op(mb)
	}
}

// newMetricData creates new pdata.Metrics and sets the InstrumentationLibrary
// name on the ResourceMetrics.
func (mb *MetricsBuilder) newMetricData() pdata.Metrics {
	md := pdata.NewMetrics()
	return md
}

// Attributes contains the possible metric attributes that can be used.
var Attributes = struct {
	// BufferPoolData (The status of buffer pool data.)
	BufferPoolData string
	// BufferPoolOperations (The buffer pool operations types.)
	BufferPoolOperations string
	// BufferPoolPages (The buffer pool pages types.)
	BufferPoolPages string
	// Command (The command types.)
	Command string
	// DoubleWrites (The doublewrite types.)
	DoubleWrites string
	// Handler (The handler types.)
	Handler string
	// Locks (The table locks type.)
	Locks string
	// LogOperations (The log operation types.)
	LogOperations string
	// Operations (The operation types.)
	Operations string
	// PageOperations (The page operation types.)
	PageOperations string
	// RowLocks (The row lock type.)
	RowLocks string
	// RowOperations (The row operation type.)
	RowOperations string
	// Sorts (The sort count type.)
	Sorts string
	// Threads (The thread count type.)
	Threads string
}{
	"status",
	"operation",
	"kind",
	"command",
	"kind",
	"kind",
	"kind",
	"operation",
	"operation",
	"operation",
	"kind",
	"operation",
	"kind",
	"kind",
}

// A is an alias for Attributes.
var A = Attributes

// AttributeBufferPoolData are the possible values that the attribute "buffer_pool_data" can have.
var AttributeBufferPoolData = struct {
	Dirty string
	Clean string
}{
	"dirty",
	"clean",
}

// AttributeBufferPoolOperations are the possible values that the attribute "buffer_pool_operations" can have.
var AttributeBufferPoolOperations = struct {
	ReadAheadRnd     string
	ReadAhead        string
	ReadAheadEvicted string
	ReadRequests     string
	Reads            string
	WaitFree         string
	WriteRequests    string
}{
	"read_ahead_rnd",
	"read_ahead",
	"read_ahead_evicted",
	"read_requests",
	"reads",
	"wait_free",
	"write_requests",
}

// AttributeBufferPoolPages are the possible values that the attribute "buffer_pool_pages" can have.
var AttributeBufferPoolPages = struct {
	Data string
	Free string
	Misc string
}{
	"data",
	"free",
	"misc",
}

// AttributeCommand are the possible values that the attribute "command" can have.
var AttributeCommand = struct {
	Execute      string
	Close        string
	Fetch        string
	Prepare      string
	Reset        string
	SendLongData string
}{
	"execute",
	"close",
	"fetch",
	"prepare",
	"reset",
	"send_long_data",
}

// AttributeDoubleWrites are the possible values that the attribute "double_writes" can have.
var AttributeDoubleWrites = struct {
	PagesWritten string
	Writes       string
}{
	"pages_written",
	"writes",
}

// AttributeHandler are the possible values that the attribute "handler" can have.
var AttributeHandler = struct {
	Commit            string
	Delete            string
	Discover          string
	ExternalLock      string
	MrrInit           string
	Prepare           string
	ReadFirst         string
	ReadKey           string
	ReadLast          string
	ReadNext          string
	ReadPrev          string
	ReadRnd           string
	ReadRndNext       string
	Rollback          string
	Savepoint         string
	SavepointRollback string
	Update            string
	Write             string
}{
	"commit",
	"delete",
	"discover",
	"external_lock",
	"mrr_init",
	"prepare",
	"read_first",
	"read_key",
	"read_last",
	"read_next",
	"read_prev",
	"read_rnd",
	"read_rnd_next",
	"rollback",
	"savepoint",
	"savepoint_rollback",
	"update",
	"write",
}

// AttributeLocks are the possible values that the attribute "locks" can have.
var AttributeLocks = struct {
	Immediate string
	Waited    string
}{
	"immediate",
	"waited",
}

// AttributeLogOperations are the possible values that the attribute "log_operations" can have.
var AttributeLogOperations = struct {
	Waits         string
	WriteRequests string
	Writes        string
}{
	"waits",
	"write_requests",
	"writes",
}

// AttributeOperations are the possible values that the attribute "operations" can have.
var AttributeOperations = struct {
	Fsyncs string
	Reads  string
	Writes string
}{
	"fsyncs",
	"reads",
	"writes",
}

// AttributePageOperations are the possible values that the attribute "page_operations" can have.
var AttributePageOperations = struct {
	Created string
	Read    string
	Written string
}{
	"created",
	"read",
	"written",
}

// AttributeRowLocks are the possible values that the attribute "row_locks" can have.
var AttributeRowLocks = struct {
	Waits string
	Time  string
}{
	"waits",
	"time",
}

// AttributeRowOperations are the possible values that the attribute "row_operations" can have.
var AttributeRowOperations = struct {
	Deleted  string
	Inserted string
	Read     string
	Updated  string
}{
	"deleted",
	"inserted",
	"read",
	"updated",
}

// AttributeSorts are the possible values that the attribute "sorts" can have.
var AttributeSorts = struct {
	MergePasses string
	Range       string
	Rows        string
	Scan        string
}{
	"merge_passes",
	"range",
	"rows",
	"scan",
}

// AttributeThreads are the possible values that the attribute "threads" can have.
var AttributeThreads = struct {
	Cached    string
	Connected string
	Created   string
	Running   string
}{
	"cached",
	"connected",
	"created",
	"running",
}
