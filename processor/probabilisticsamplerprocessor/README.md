# Probabilistic Sampling Processor

<!-- status autogenerated section -->
| Status        |           |
| ------------- |-----------|
| Stability     | [alpha]: logs   |
|               | [beta]: traces   |
| Distributions | [core], [contrib], [aws], [grafana], [observiq], [splunk], [sumo] |
| Issues        | [![Open issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector-contrib?query=is%3Aissue%20is%3Aopen%20label%3Aprocessor%2Fprobabilisticsampler%20&label=open&color=orange&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues?q=is%3Aopen+is%3Aissue+label%3Aprocessor%2Fprobabilisticsampler) [![Closed issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector-contrib?query=is%3Aissue%20is%3Aclosed%20label%3Aprocessor%2Fprobabilisticsampler%20&label=closed&color=blue&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues?q=is%3Aclosed+is%3Aissue+label%3Aprocessor%2Fprobabilisticsampler) |
| [Code Owners](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/CONTRIBUTING.md#becoming-a-code-owner)    | [@jpkrohling](https://www.github.com/jpkrohling) |

[alpha]: https://github.com/open-telemetry/opentelemetry-collector#alpha
[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta
[core]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol
[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib
[aws]: https://github.com/aws-observability/aws-otel-collector
[grafana]: https://github.com/grafana/agent
[observiq]: https://github.com/observIQ/observiq-otel-collector
[splunk]: https://github.com/signalfx/splunk-otel-collector
[sumo]: https://github.com/SumoLogic/sumologic-otel-collector
<!-- end autogenerated section -->

The probabilistic sampler processor supports several modes of sampling
for spans and log records.  Sampling is performed on a per-request
basis, considering individual items statelessly.  For whole trace
sampling, see
[tailsamplingprocessor](../tailsamplingprocessor/README.md/).

For trace spans, this sampler supports probabilistic sampling based on
a configured sampling percentage applied to the TraceID.  In addition,
the sampler recognizes a `sampling.priority` annotation, which can
force the sampler to apply 0% or 100% sampling.

For log records, this sampler can be configured to use the embedded
TraceID and follow the same logic as applied to spans.  When the
TraceID is not defined, the sampler can be configured to apply hashing
to a selected log record attribute.  This sampler also supports
sampling priority.

## Consistency guarantee

A consistent probability sampler is a Sampler that supports
independent sampling decisions for each span or log record in a group
(e.g. by TraceID), maintaining that traces will be complete with a
certain minimum probability.

Consistent probability sampling requires that for any span in a given
trace, if a Sampler with lesser sampling probability selects the span
for sampling, then the span would also be selected by a Sampler
configured with greater sampling probability.

## Sampling randomness

To achieve consistency, sampling randomness is taken from a
deterministic aspsect of the input data.  For traces pipelines, the
source of randomness is always the TraceID.  For logs pipelines, the
source of randomness can be the TraceID or another log record
attribute, if configured.

For log records, the `attribute_source` and `from_attribute` fields determine the
source of randomness used for log records.  When `attribute_source` is
set to `traceID`, the TraceID will be used.  When `attribute_source`
is set to `record` or the TraceID field is absent, the value of
`from_attribute` is taken as the source of randomness (if configured).

## Sampling priority

The `sampling.priority` semantic convention takes precedence over the
probabilistic decision for all modes.

ðŸ›‘ Compatibility note: Logs and Traces have different behavior.

In traces pipelines, when the priority attribute has value 0, the
configured probability will by modified to 0% and the item will not
pass the sampler.  When the priority attribute is non-zero the
configured probability will modified to 100%.  The sampling priority
attribute is fixed, `sampling.priority`.

In logs pipelines, when the priority attribute has value 0, the
configured probability will by modified to 0%, and the item will not
pass the sampler.  Otherwise, the sampling priority attribute is
interpreted as a percentage, with values >= 100 equal to 100%
sampling.  The sampling priority is configurable, via
`from_attribute`.

## Mode Selection

There are three sampling modes available.  All modes are consistent.

### Hash seed

The hash seed method uses the FNV hash function applied to either a
Trace ID (spans, log records), or to the value of a specified
attribute (only logs).  The hashed value, presumed to be random, is
compared against a threshold value that corresponds with the sampling
percentage.

Hash seed mode is used for log records when there is no TraceID available.

This mode requires configuring the `hash_seed` field.  This mode is
enabled when the `hash_seed` field is not zero.

In order for hashing to work, all collectors for a given tier
(e.g. behind the same load balancer) must have the same
`hash_seed`. It is also possible to leverage a different `hash_seed`
at different collector tiers to support additional sampling
requirements.

### Proportional

OpenTelemetry specifies a consistent sampling mechanism using 56 bits
of randomness, which may be obtained from the Trace ID according to
the W3C Trace Context Level 2 specification.  Randomness can also be
explicly encoding in the OpenTelemetry `tracestate` field, where it is
known as the R-value.

This mode is named because it reduces the number of items transmitted
proportionally, according to the sampling probability.  In this mode,
items are selected for sampling without considering how much they were
already sampled by preceding samplers.

This mode is selected when the `hash_seed` field is set to zero.

### Equalizing

This mode uses the same randomness mechanism as the propotional
sampling mode, in this case considering how much each item was already
sampled by preceding samplers.  This mode can be used to lower
sampling probability to a minimum value across a whole pipeline, which
has the effect of increasing trace completeness.

## Configuration

The following configuration options can be modified:
- `sampling_percentage` (required): Percentage at which logs are sampled; >= 100 samples all logs, 0 rejects all logs.
- `mode` (default = "", optional): The optional sampling mode.  One of "hash_seed", "equalizing", and "propotional".
- `hash_seed` (no default, optional): An integer used to compute the hash algorithm. Note that all collectors for a given tier (e.g. behind the same load balancer) should have the same hash_seed.
- `sampling_precision` (default = 4, optional): The number of digits of precision used to encode thesampling probability.

- `attribute_source` (default = traceID, optional): defines where to look for the attribute in from_attribute. The allowed values are `traceID` or `record`.
- `from_attribute` (default = null, optional): The optional name of a log record attribute used for sampling purposes, such as a unique log record ID. The value of the attribute is only used if the trace ID is absent or if `attribute_source` is set to `record`.
- `sampling_priority` (default = null, optional): The optional name of a log record attribute used to set a different sampling priority from the `sampling_percentage` setting. 0 means to never sample the log record, and >= 100 means to always sample the log record.

Examples:

@@@

Sample 15% of log records

```yaml
processors:
  probabilistic_sampler:
    mode: hash_seed
    sampling_percentage: 15
```

Sample logs according to their logID attribute:

```yaml
processors:
  probabilistic_sampler:
    mode: hash_seed
    sampling_percentage: 15
    attribute_source: record # possible values: one of record or traceID
    from_attribute: logID # value is required if the source is not traceID
```

Sample logs according to the attribute `priority`:

```yaml
processors:
  probabilistic_sampler:
    mode: hash_seed
    sampling_percentage: 15
    sampling_priority: priority
```

For example, to configure the proportional sampler, simply omit the
`hash_seed` field:

```
processors:
  probabilistic_sampler:
	# no hash_seed is set, uses proportional consistent by default
    sampling_percentage: 10
```

For example, to configure an equalizing sampler, set the mode explicitly:

```
processors:
  probabilistic_sampler:
	mode: equalizing
    sampling_percentage: 10
```

The optional `sampling_precision` field determines how many
hexadecimal digits are used to express the sampling rejection
threshold.  By default, 5 hex digits are used.  For example, 60%
sampling is approximated as "66666" with precision 3, because the
rejection threshold of 40% is approximated by `0x66666` out of
`0x100000`, indicating a sampling probability of precisely
60.000038147%

## Detailed examples

Refer to [config.yaml](./testdata/config.yaml) for detailed examples
on using the processor.
