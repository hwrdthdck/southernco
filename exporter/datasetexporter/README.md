# DataSet Exporter

<!-- status autogenerated section -->
| Status        |           |
| ------------- |-----------|
| Stability     | [alpha]: logs, traces   |
| Distributions | [contrib] |
| Issues        | ![Open issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector-contrib?query=is%3Aissue%20is%3Aopen%20label%3Aexporter%2Fdataset%20&label=open&color=orange&logo=opentelemetry) ![Closed issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector-contrib?query=is%3Aissue%20is%3Aclosed%20label%3Aexporter%2Fdataset%20&label=closed&color=blue&logo=opentelemetry) |

[alpha]: https://github.com/open-telemetry/opentelemetry-collector#alpha
[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib
<!-- end autogenerated section -->

This exporter sends logs to [DataSet](https://www.dataset.com/).

See the [Getting Started](https://app.scalyr.com/help/getting-started) guide.

## Configuration

### Required Settings

- `dataset_url` (no default): The URL of the DataSet API that ingests the data. Most likely https://app.scalyr.com.
- `api_key` (no default): The "Log Write" API Key required to use API. Instructions how to get [API key](https://app.scalyr.com/help/api-keys).

If you do not want to specify `api_key` in the file, you can use the [builtin functionality](https://opentelemetry.io/docs/collector/configuration/#configuration-environment-variables) and use `api_key: ${env:DATASET_API_KEY}`.

### Optional Settings

- `buffer`:
  - `max_lifetime` (default = 5s): The maximum delay between sending batches from the same source.
  - `group_by` (default = []): The list of attributes based on which events should be grouped.
  - `retry_initial_interval` (default = 5s): Time to wait after the first failure before retrying.
  - `retry_max_interval` (default = 30s): Is the upper bound on backoff.
  - `retry_max_elapsed_time` (default = 300s): Is the maximum amount of time spent trying to send a buffer.
- `logs`:
  - `export_resource_info_on_event` (default = false): Include resource info to DataSet Event while exporting Logs. This is especially useful when reducing DataSet billable log volume.
- `server_host`:
  - `use_attributes` (default = []): Use the value in the specified attributes as server host in events.
  - `server_host` (default = ''): Use the specified value as server host in events.
  - `use_host_name` (default = true): Use the `hostname` of the node as server host used in events.
- `retry_on_failure`: See [retry_on_failure](https://github.com/open-telemetry/opentelemetry-collector/blob/main/exporter/exporterhelper/README.md)
- `sending_queue`: See [sending_queue](https://github.com/open-telemetry/opentelemetry-collector/blob/main/exporter/exporterhelper/README.md)
- `timeout`: See [timeout](https://github.com/open-telemetry/opentelemetry-collector/blob/main/exporter/exporterhelper/README.md)


### Example

```yaml

exporters:
  dataset:
    # DataSet API URL
    dataset_url: https://app.scalyr.com
    # API Key
    api_key: your_api_key
    buffer:
      # Send buffer to the API at least every 10s
      max_lifetime: 10s
      # Group data based on these attributes
      group_by:
        - attributes.container_id
    server_host:
      # Search for the server host in attributes.
      # Use the value from server and then from hostname
      use_attributes:
        - server
        - hostname
      # If these attributes are not specified or empty,
      # use the value from the env variable SERVER_HOST
      use_host: ${env:SERVER_HOST}
      # If it's not set, use the hostname value
      use_host_name: true

service:
  pipelines:
    logs:
      receivers: [otlp]
      processors: [batch]
      # add dataset among your exporters
      exporters: [dataset]
    traces:
      receivers: [otlp]
      processors: [batch]
      # add dataset among your exporters
      exporters: [dataset]
```
